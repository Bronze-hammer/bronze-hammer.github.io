{"meta":{"title":"徐子辉的个人站点","subtitle":"Change Myself From Now ON.","description":null,"author":"xuzh","url":"http://yoursite.com","root":"/"},"pages":[{"title":"about","date":"2019-01-22T00:54:44.000Z","updated":"2023-01-20T12:54:39.471Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"我本身就是一个不喜欢主动的人， 虽然灵魂有趣，但是不爱表达， 死倔，也慢热， 遇到懂我的人是幸运， 遇不到也是正常， 沉默，喜欢独处，三观正， 比你想象的深情， 也比你以为的冷漠。"},{"title":"categories","date":"2019-01-22T01:00:35.000Z","updated":"2022-07-25T06:26:34.862Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-01-22T01:00:21.000Z","updated":"2022-07-25T06:26:34.862Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ArrayList.retainAll()方法解析","slug":"ArrayList-retainAll-方法解析","date":"2023-03-09T05:57:09.000Z","updated":"2023-03-10T08:40:08.263Z","comments":true,"path":"2023/03/09/ArrayList-retainAll-方法解析/","link":"","permalink":"http://yoursite.com/2023/03/09/ArrayList-retainAll-方法解析/","excerpt":"在工作中，用java.util.ArrayList.retainAll(Collection&lt;?&gt;)方法判断两个list集合是否有交集（两个list是否有相同的元素）。如果两个集合有相同元素，那么retainAll返回true。但是如果两个集合的元素完全相同，返回的结果却是false,而如果两个list集合的元素都不一样，retainAll却返回true。 这是怎么回事呢？","text":"在工作中，用java.util.ArrayList.retainAll(Collection&lt;?&gt;)方法判断两个list集合是否有交集（两个list是否有相同的元素）。如果两个集合有相同元素，那么retainAll返回true。但是如果两个集合的元素完全相同，返回的结果却是false,而如果两个list集合的元素都不一样，retainAll却返回true。 这是怎么回事呢？ 先来看看ArrayList.retainAll(Collection&lt;?&gt;) 源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Retains only the elements in this list that are contained in the * specified collection. In other words, removes from this list all * of its elements that are not contained in the specified collection. * * @param c collection containing elements to be retained in this list * @return &#123;@code true&#125; if this list changed as a result of the call * @throws ClassCastException if the class of an element of this list * is incompatible with the specified collection * (&lt;a href=\"Collection.html#optional-restrictions\"&gt;optional&lt;/a&gt;) * @throws NullPointerException if this list contains a null element and the * specified collection does not permit null elements * (&lt;a href=\"Collection.html#optional-restrictions\"&gt;optional&lt;/a&gt;), * or if the specified collection is null * @see Collection#contains(Object) */public boolean retainAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); return batchRemove(c, true);&#125;private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) &#123; final Object[] elementData = this.elementData; int r = 0, w = 0; boolean modified = false; try &#123; for (; r &lt; size; r++) if (c.contains(elementData[r]) == complement) elementData[w++] = elementData[r]; &#125; finally &#123; // Preserve behavioral compatibility with AbstractCollection, // even if c.contains() throws. if (r != size) &#123; System.arraycopy(elementData, r, elementData, w, size - r); w += size - r; &#125; if (w != size) &#123; // clear to let GC do its work for (int i = w; i &lt; size; i++) elementData[i] = null; modCount += size - w; size = w; modified = true; &#125; &#125; return modified;&#125; retainAll注释的第一句已经基本交代了方法的功能 Retains only the elements in this list that are contained in the specified collection. In other words, removes from this list all of its elements that are not contained in the specified collection. 仅保留此列表中包含在指定集合中的元素。换句话说，从此列表中删除未包含在指定集合中的所有元素。 123for (; r &lt; size; r++) if (c.contains(elementData[r]) == complement) elementData[w++] = elementData[r]; 遍历此列表 elementData 中的元素，判断是否与 c集合有相同元素，把相同的元素覆盖在此列表的第一个地址上，以此类推。以w 记录相同元素的个数。 回到刚开始的问题上，为什么两个集合的元素都一样，结果返回 false， 两个集合元素都不一样，结果返回 true 呢？ 12345678if (w != size) &#123; // clear to let GC do its work for (int i = w; i &lt; size; i++) elementData[i] = null; modCount += size - w; size = w; modified = true;&#125; 如果两个集合的元素完全一样，w == size，这样会跳过判断，直接返回 modified 的初始值 false; 如果两个集合的元素都不一样，w != size满足条件，modified 被赋值为true，返回结果即为true。 所以单纯用ArrayList.retainAll()方法，根据返回值true/false,判断两个集合是否有相同元素，是不准确的。 可以使用另一个方法 java.util.Collections.disjoint(Collection&lt;?&gt; c1, Collection&lt;?&gt; c2)，两个指定collection中没有相同的元素，则返回true。如果其中一个集合为null，则抛出NullPointerException。 源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889/** * Returns &#123;@code true&#125; if the two specified collections have no * elements in common. * * &lt;p&gt;Care must be exercised if this method is used on collections that * do not comply with the general contract for &#123;@code Collection&#125;. * Implementations may elect to iterate over either collection and test * for containment in the other collection (or to perform any equivalent * computation). If either collection uses a nonstandard equality test * (as does a &#123;@link SortedSet&#125; whose ordering is not &lt;em&gt;compatible with * equals&lt;/em&gt;, or the key set of an &#123;@link IdentityHashMap&#125;), both * collections must use the same nonstandard equality test, or the * result of this method is undefined. * * &lt;p&gt;Care must also be exercised when using collections that have * restrictions on the elements that they may contain. Collection * implementations are allowed to throw exceptions for any operation * involving elements they deem ineligible. For absolute safety the * specified collections should contain only elements which are * eligible elements for both collections. * * &lt;p&gt;Note that it is permissible to pass the same collection in both * parameters, in which case the method will return &#123;@code true&#125; if and * only if the collection is empty. * * @param c1 a collection * @param c2 a collection * @return &#123;@code true&#125; if the two specified collections have no * elements in common. * @throws NullPointerException if either collection is &#123;@code null&#125;. * @throws NullPointerException if one collection contains a &#123;@code null&#125; * element and &#123;@code null&#125; is not an eligible element for the other collection. * (&lt;a href=\"Collection.html#optional-restrictions\"&gt;optional&lt;/a&gt;) * @throws ClassCastException if one collection contains an element that is * of a type which is ineligible for the other collection. * (&lt;a href=\"Collection.html#optional-restrictions\"&gt;optional&lt;/a&gt;) * @since 1.5 */public static boolean disjoint(Collection&lt;?&gt; c1, Collection&lt;?&gt; c2) &#123; // The collection to be used for contains(). Preference is given to // the collection who's contains() has lower O() complexity. Collection&lt;?&gt; contains = c2; // The collection to be iterated. If the collections' contains() impl // are of different O() complexity, the collection with slower // contains() will be used for iteration. For collections who's // contains() are of the same complexity then best performance is // achieved by iterating the smaller collection. Collection&lt;?&gt; iterate = c1; // Performance optimization cases. The heuristics: // 1. Generally iterate over c1. // 2. If c1 is a Set then iterate over c2. // 3. If either collection is empty then result is always true. // 4. Iterate over the smaller Collection. if (c1 instanceof Set) &#123; // Use c1 for contains as a Set's contains() is expected to perform // better than O(N/2) iterate = c2; contains = c1; &#125; else if (!(c2 instanceof Set)) &#123; // Both are mere Collections. Iterate over smaller collection. // Example: If c1 contains 3 elements and c2 contains 50 elements and // assuming contains() requires ceiling(N/2) comparisons then // checking for all c1 elements in c2 would require 75 comparisons // (3 * ceiling(50/2)) vs. checking all c2 elements in c1 requiring // 100 comparisons (50 * ceiling(3/2)). int c1size = c1.size(); int c2size = c2.size(); if (c1size == 0 || c2size == 0) &#123; // At least one collection is empty. Nothing will match. return true; &#125; if (c1size &gt; c2size) &#123; iterate = c2; contains = c1; &#125; &#125; for (Object e : iterate) &#123; if (contains.contains(e)) &#123; // Found a common element. Collections are not disjoint. return false; &#125; &#125; // No common elements were found. return true;&#125;","categories":[{"name":"代码人生","slug":"代码人生","permalink":"http://yoursite.com/categories/代码人生/"}],"tags":[{"name":"ArrayList","slug":"ArrayList","permalink":"http://yoursite.com/tags/ArrayList/"},{"name":"retainAll()","slug":"retainAll","permalink":"http://yoursite.com/tags/retainAll/"}]},{"title":"浅析Field-injection-is-not-recommended","slug":"浅析Field-injection-is-not-recommended","date":"2023-02-22T09:36:46.000Z","updated":"2023-02-27T03:32:43.642Z","comments":true,"path":"2023/02/22/浅析Field-injection-is-not-recommended/","link":"","permalink":"http://yoursite.com/2023/02/22/浅析Field-injection-is-not-recommended/","excerpt":"IDEA运行SpringBoot项目，遇到以下有关 @Autowired 注解的警告：Field injection is not recommended . 这篇文章浅析这个问题，为什么会有这样的提示？为什么字段注入的方式不推荐？","text":"IDEA运行SpringBoot项目，遇到以下有关 @Autowired 注解的警告：Field injection is not recommended . 这篇文章浅析这个问题，为什么会有这样的提示？为什么字段注入的方式不推荐？ 当前的 spring framework (5.0.3) 文档仅定义了两种主要的注入类型1 DI exists in two major variants: Constructor-based dependency injection and Setter-based dependency injection. 基于构造函数的依赖注入:在基于构造函数的依赖注入中，类构造函数被注释@Autowired并包含可变数量的参数以及要注入的对象。 123456789101112public class SimpleMovieLister &#123; // the SimpleMovieLister has a dependency on a MovieFinder private final MovieFinder movieFinder; // a constructor so that the Spring container can inject a MovieFinder public SimpleMovieLister(MovieFinder movieFinder) &#123; this.movieFinder = movieFinder; &#125; // business logic that actually uses the injected MovieFinder is omitted...&#125; 基于构造函数的注入的主要优点是您可以将注入的字段声明为final，因为它们将在类实例化期间启动。这对于所需的依赖项很方便。 基于Setter的依赖注入:在基于 setter 的依赖注入中，setter 方法用@Autowired. 一旦使用无参数构造函数或无参数静态工厂方法实例化 Bean，Spring 容器将调用这些 setter 方法以注入 Bean 的依赖项。 123456789101112public class SimpleMovieLister &#123; // the SimpleMovieLister has a dependency on the MovieFinder private MovieFinder movieFinder; // a setter method so that the Spring container can inject a MovieFinder public void setMovieFinder(MovieFinder movieFinder) &#123; this.movieFinder = movieFinder; &#125; // business logic that actually uses the injected MovieFinder is omitted...&#125; 但实际上还有第三种，也是被广泛应用的 基于字段的依赖注入:在基于字段的依赖注入中，字段/属性用@Autowired. 实例化类后，Spring 容器将设置这些字段。 1234567@Componentpublic class ConstructorBasedInjection &#123; @Autowired private InjectedBean injectedBean;&#125; 这是注入依赖项的最简洁的方法，因为它避免了添加样板代码，并且无需为类声明构造函数。代码看起来不错，简洁明了，但正如代码检查员已经提示我们的那样，这种方法有一些缺点。 那么为什么不推荐使用基于字段的依赖注入？ 基于字段的依赖注入缺点2 不允许不可变字段声明 基于字段的依赖注入不适用于声明为 final/immutable 的字段，因为这些字段必须在类实例化时实例化。声明不可变依赖项的唯一方法是使用基于构造函数的依赖项注入。 违反了单一责任原则 如您所知，在面向对象的计算机编程中，SOLID3首字母缩略词定义了五个设计原则，这些原则将使您的代码易于理解、灵活和可维护。SOLID中的S代表单一职责原则，这意味着一个类应该只负责软件应用程序功能的单个部分，并且它的所有服务都应该与该职责严格对齐。 使用基于字段的依赖注入，很容易在你的类中有很多依赖，一切看起来都很好。如果改为使用基于构造函数的依赖注入，随着更多的依赖项被添加到你的类中，构造函数变得越来越大。拥有一个包含十个以上参数的构造函数是一个明显的标志，表明该类有太多协作者，这可能是开始将类拆分为更小且更易于维护的部分的好时机。 这里要说明：基于构造函数依赖注入，并不说能够解决类里面的过多依赖的问题。而是说能够直观的提示我们：这个类被注入了太多的依赖，你该停下来，优化并拆分你的业务逻辑了！ 因此，尽管字段注入并不直接导致打破单一责任原则，但它肯定有助于隐藏信号，否则这些信号会非常明显。 与依赖注入容器紧密耦合 使用基于字段的注入的主要原因是避免getter和setter的样板代码或为您的类创建构造函数。最后，这意味着可以设置这些字段的唯一方法是通过Spring容器实例化类并使用反射注入它们，否则字段将保持为 null 并且您的类将被破坏/无用。 依赖注入设计模式将类依赖的创建与类本身分开，将此责任转移到类注入器，允许程序设计松散耦合并遵循单一职责和依赖倒置原则（再次是SOLID）。因此，最终通过自动装配其字段实现的类解耦会因再次与类注入器（在本例中为 Spring）耦合而丢失，从而使该类在 Spring 容器之外无用。 这意味着如果你想在应用程序容器之外使用你的类，例如用于单元测试，你必须使用 Spring 容器来实例化你的类，因为没有其他可能的方法（除了反射）来设置自动装配的字段。 隐藏的依赖 使用依赖注入模式时，受影响的类应该使用公共接口清楚地公开这些依赖关系，方法是在构造函数中公开所需的依赖关系，或者使用方法（setter）公开可选的依赖关系。当使用基于字段的依赖注入时，该类本质上将这些依赖隐藏到外部世界。 结论 我们已经看到应该尽可能避免基于字段的注入，因为它有许多缺点，无论它看起来多么优雅。推荐的方法是使用基于构造函数和基于设置器的依赖注入。对于必需的依赖项，建议使用基于构造函数的注入，以允许它们不可变并防止它们为空。对于可选的依赖项，建议使用基于 Setter 的注入。 补充 2023-02-27 构造器依赖注入，如果要注入的属性太多，构造方法会很臃肿，可以在类上加 @RequiredArgsConstructor 注解，这个注解会把final修饰的（或者@NonNull注解的）属性构建默认的构造方法。 12345678@RequiredArgsConstructorpublic class SimpleMovieLister &#123; // the SimpleMovieLister has a dependency on a MovieFinder private final MovieFinder movieFinder; // business logic that actually uses the injected MovieFinder is omitted...&#125; 从Spring Framework 4.3开始，如果目标bean只定义了一个构造函数，则不再需要在这样的构造函数上使用@Autowired注释。但是，如果有几个可用的构造函数，至少必须用@Autowired注释其中一个，以便指示容器使用哪个构造函数4。 《Spring Framework Documentation 1.4.1. Dependency Injection》↩︎ 《Field injection is not recommended – Spring IOC》↩︎ 《Wiki SOLID》↩︎ 《Core Technology:1.9.2. Using @Autowired》↩︎","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://yoursite.com/categories/编程语言/"}],"tags":[{"name":"field injection","slug":"field-injection","permalink":"http://yoursite.com/tags/field-injection/"}]},{"title":"日常工作中Java.Stream流操作汇总","slug":"日常工作中Java-Stream流操作汇总","date":"2023-02-08T02:29:31.000Z","updated":"2023-02-22T08:37:49.275Z","comments":true,"path":"2023/02/08/日常工作中Java-Stream流操作汇总/","link":"","permalink":"http://yoursite.com/2023/02/08/日常工作中Java-Stream流操作汇总/","excerpt":"Java 8 API添加了一个新的抽象称为流Stream，以一种声明的方式处理数据。Stream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。Stream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。这种风格将要处理的元素集合看作一种流， 流在管道中传输， 并且可以在管道的节点上进行处理， 比如筛选， 排序，聚合等。元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation)得到前面处理的结果。 ————《菜鸟教程》 本片文章记录了工作中常用的Stream流操作，方便之后回顾。","text":"Java 8 API添加了一个新的抽象称为流Stream，以一种声明的方式处理数据。Stream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。Stream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。这种风格将要处理的元素集合看作一种流， 流在管道中传输， 并且可以在管道的节点上进行处理， 比如筛选， 排序，聚合等。元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation)得到前面处理的结果。 ————《菜鸟教程》 本片文章记录了工作中常用的Stream流操作，方便之后回顾。 1.对List集合，取User中的一个元素，形成新的List集合 12// List&lt;User&gt; userList;List&lt;String&gt; userNameList = userList.stream.map(User::getUserName).collect(Collectors.toList); 2.去重 对集合 List userList 内的对象去重（实体类User 使用Lombok 插件的@Data 注解，自动覆写 equals 和 hashCode 方法） 12// List&lt;User&gt; userList;List&lt;User&gt; newUserList = userList.stream().distinct().collect(Collectors.toList()); 3.过滤 过滤集合 List&lt;SysOptionData&gt; optionDataList 对象label为 \"zhangsan\" 的数据 12345678List&lt;SysOptionData&gt; resultList = optionDataList.stream().filter( optionData -&gt; \"zhangsan\".equals(optionData.getOptionLabel())).collect(Collectors.toList());// 返回过滤后的集合第一条数据List&lt;SysOptionData&gt; resultList = optionDataList.stream().filter( optionData -&gt; \"zhangsan\".equals(optionData.getOptionLabel())).findFirst(); 4.List集合转String字符串 12345// List&lt;User&gt; 包含User实体的集合，只提取username拼成一个字符串，以“，”隔开String username = userList.stream().map(User::getUsername()).collect(Collectors.joining(\",\")); // List&lt;String&gt; usernameListString username = usernameList.stream().collect(Collectors.joining(\",\")); 5.匹配两个List集合，返回新的List集合 比如有两个集合，List&lt;User&gt;、 List&lt;Address&gt; List&lt;User&gt; 集合的数据 name age address zhangsan 15 null tom 16 null jom 20 null List&lt;Address&gt; 集合的数据 name address zhangsan China tom USA jary Japan 对比着两个集合，以List&lt;User&gt;为主体，按照name字段匹配List&lt;Address&gt;集合，把匹配到的Address对象的address字段的值设置到User对象的address字段 123456789101112131415List&lt;User&gt; list = userList.stream() .map(u -&gt; &#123; return addrList.stream() .filter(a -&gt; &#123; return a.getName().equals(u.getName()); &#125;).map(a -&gt; &#123; u.setAddress(a.getAddress()); return u; &#125;).collect(Collectors.toList()); &#125;) .flatMap(List::stream) .collect(Collectors.toList());for (User user : list) &#123; System.out.println(user.toString());&#125; 结果输出： 12User [name=zhangsan, age=15, address=China]User [name=tom, age=16, address=USA] 需要注意的是，结果只会返回匹配到的数据 6.Stream map和flatMap的区别 6.1 stream.map Returns a stream consisting of the results of applying the givenfunction to the elements of this stream. 返回一个流，由将给定函数应用于该流的元素的结果组成。 示例： 12List&lt;String&gt; nameList = Stream.of(\"ZhangSan\", \"Tom\").collect(Collectors.toList());nameList.stream().map(n -&gt; n + \", welcome\").forEach(e -&gt; System.out.println(e)); 输出： 12ZhangSan, welcomeTom, welcome 请注意另一种情况： 12345678List&lt;String&gt; nameList = Stream.of(\"ZhangSan\", \"Tom\").collect(Collectors.toList());List&lt;String[]&gt; list = nameList.stream().map(n -&gt; n.split(\"\")).collect(Collectors.toList());for (String[] strings : list) &#123; for (int i = 0; i &lt; strings.length; i++) &#123; System.out.print(strings[i] + \" \"); &#125; System.out.println();&#125; 输出： 12Z h a n g S a n T o m map操作就是把一种操作运算，映射到一个序列的每一个元素上。以每个元素为一个单位，运算的结果也是相互独立的，所以返回的是List&lt;String[]&gt;，而不是List&lt;String&gt; 6.2 stream.flatMap Returns a stream consisting of the results of replacing each element ofthis stream with the contents of a mapped stream produced by applyingthe provided mapping function to each element. Each mapped stream is closed after its contentshave been placed into this stream. (If a mapped stream is nullan empty stream is used, instead.) 返回一个流，由将提供的映射函数应用到每个元素所产生的映射流的内容替换此流中的每个元素的结果组成。每个映射的流在其内容被放入该流后将被关闭。(如果映射流为null，则使用空流。) The flatMap() operation has the effect of applying a one-to-manytransformation to the elements of the stream, and then flattening theresulting elements into a new stream. flatMap()操作的效果是对流的元素应用一对多的转换，然后将产生的元素平铺成一个新的流。 示例： 123456List&lt;String&gt; nameList = Stream.of(\"ZhangSan\", \"Tom\").collect(Collectors.toList());List&lt;String&gt; list = nameList.stream() .map(n -&gt; n.split(\"\")) .flatMap(e -&gt; Arrays.stream(e)) .collect(Collectors.toList());System.out.println(list.toString()); 输出： 1[Z, h, a, n, g, S, a, n, T, o, m] 7.List集合转Map List&lt;User&gt; 集合，设置 User.name 作为Map的key，User对象作为value，转换为Map集合 12Map&lt;String, User&gt; userMap = userList.stream() .collect(Collectors.toMap(User::getName, Function.identity())); 8.针对List列表，按照指定元素分组，生成新的Map集合 例如对下面List列表的数据做分组 123new User(\"zhangsan\", 12, \"Guangzhou\");new User(\"lisi\", 13, \"Shenzhen\");new User(\"tom\", 12, \"Beijing\"); 分组操作 1Map&lt;Integer, List&lt;User&gt;&gt; map = userList.stream().collect(Collectors.groupingBy(User::getAge)); 分组结果 123456789&#123; 12=[ User [name=zhangsan, age=12, address=Guangzhou], User [name=tom, age=12, address=Beijing] ], 13=[ User [name=lisi, age=13, address=Shenzhen] ]&#125;","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://yoursite.com/categories/编程语言/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"Stream","slug":"Stream","permalink":"http://yoursite.com/tags/Stream/"}]},{"title":"处理SpringCloudConfig客户端启动无法读取到配置参数","slug":"处理SpringCloudConfig客户端启动无法读取到配置参数","date":"2023-02-01T09:42:28.000Z","updated":"2023-02-02T01:39:41.198Z","comments":true,"path":"2023/02/01/处理SpringCloudConfig客户端启动无法读取到配置参数/","link":"","permalink":"http://yoursite.com/2023/02/01/处理SpringCloudConfig客户端启动无法读取到配置参数/","excerpt":"自己部署了一个Spring Cloud微服务项目，实践Spring Cloud Config分布式配置组件，按照Spring Cloud Config 资料Config：Spring Cloud分布式配置组件 先后创建了Eureka注册中心服务、 Spring Cloud Config Server服务、 Spring Cloud Config Client客户端，在最后启动 Spring Client Config Client 客户端时，客户端始终无法访问 Config Server服务，读取上传在Gitee上的配置文件的内容。 在Baidu、 Google搜索了大量资料，问题是最终解决了，但是这其中的原因，还需要继续探讨。","text":"自己部署了一个Spring Cloud微服务项目，实践Spring Cloud Config分布式配置组件，按照Spring Cloud Config 资料Config：Spring Cloud分布式配置组件 先后创建了Eureka注册中心服务、 Spring Cloud Config Server服务、 Spring Cloud Config Client客户端，在最后启动 Spring Client Config Client 客户端时，客户端始终无法访问 Config Server服务，读取上传在Gitee上的配置文件的内容。 在Baidu、 Google搜索了大量资料，问题是最终解决了，但是这其中的原因，还需要继续探讨。 Eureka注册中心和Spring Cloud Config Server的配置内容就不多讲，可参考Eureka：Spring Cloud服务注册与发现组件 和Config：Spring Cloud分布式配置组件，启动了 Config Server 服务，并用浏览器访问，上传在Gitee上的参数文件的内容是可以正常获取到的 我们重点说一下Spring Cloud Config Client的配置，yml文件配置如下： 1234567891011121314151617server: port: 3355 #端口号spring: application: name: spring-cloud-config-client #服务名 cloud: config: label: master #分支名称 name: application #配置文件名称，application-dev.yml 中的 config profile: dev #环境名 application-dev.yml 中的 dev #这里不要忘记添加 http:// 否则无法读取 uri: http://localhost:3344 #Spring Cloud Config 服务端（配置中心）地址eureka: client: #将客户端注册到 eureka 服务列表内 service-url: defaultZone: http://localhost:9900/eureka 新增Controller类，用于测试配置文件内容的读取 1234567891011121314151617181920@RestController@RequestMapping(&quot;/config/client&quot;)public class ConfigClientController &#123; @Value(&quot;$&#123;server.port&#125;&quot;) private String serverPort; @Value(&quot;$&#123;config.info&#125;&quot;) private String configInfo; @Value(&quot;$&#123;config.version&#125;&quot;) private String configVersion; @GetMapping(value = &quot;/getConfig&quot;) public String getConfig() &#123; return &quot;info：&quot; + configInfo + &quot;&lt;br/&gt;version：&quot; + configVersion + &quot;&lt;br/&gt;port：&quot; + serverPort; &#125;&#125; Spring Cloud Config Client客户端在启动的时候控制台报错： 123456789101112131415161718Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder &apos;config.info&apos; in value &quot;$&#123;config.info&#125;&quot; at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:180) ~[spring-core-5.3.23.jar:5.3.23] at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:126) ~[spring-core-5.3.23.jar:5.3.23] at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:239) ~[spring-core-5.3.23.jar:5.3.23] at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:210) ~[spring-core-5.3.23.jar:5.3.23] at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.lambda$processProperties$0(PropertySourcesPlaceholderConfigurer.java:191) ~[spring-context-5.3.23.jar:5.3.23] at org.springframework.beans.factory.support.AbstractBeanFactory.resolveEmbeddedValue(AbstractBeanFactory.java:936) ~[spring-beans-5.3.23.jar:5.3.23] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1332) ~[spring-beans-5.3.23.jar:5.3.23] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311) ~[spring-beans-5.3.23.jar:5.3.23] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656) ~[spring-beans-5.3.23.jar:5.3.23] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639) ~[spring-beans-5.3.23.jar:5.3.23] at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119) ~[spring-beans-5.3.23.jar:5.3.23] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399) ~[spring-beans-5.3.23.jar:5.3.23] ... 16 common frames omittedDisconnected from the target VM, address: &apos;127.0.0.1:54601&apos;, transport: &apos;socket&apos;Process finished with exit code 1 遂检查配置文件，对照资料教程看是不是自己写错了。在检查 Config Client 模块的配置文件时发现，资料上创建的配置文件名称是 bootstrap.yml 而非 application.yml 遂把配置文件名改为 bootstrap.yml， 重新启动，发现没有报之前的错误了。但是服务也没有正常运行起来，而是直接停止了，控制台输出： 123456789101112131415161718192023-02-01 20:42:52.002 INFO 15096 --- [ main] com.netflix.discovery.DiscoveryClient : Starting heartbeat executor: renew interval is: 302023-02-01 20:42:52.005 INFO 15096 --- [ main] c.n.discovery.InstanceInfoReplicator : InstanceInfoReplicator onDemand update allowed rate per min is 42023-02-01 20:42:52.012 INFO 15096 --- [ main] com.netflix.discovery.DiscoveryClient : Discovery Client initialized at timestamp 1675255372011 with initial instances count: 22023-02-01 20:42:52.015 INFO 15096 --- [ main] o.s.c.n.e.s.EurekaServiceRegistry : Registering application SPRING-CLOUD-CONFIG-CLIENT with eureka with status UP2023-02-01 20:42:52.016 INFO 15096 --- [ main] com.netflix.discovery.DiscoveryClient : Saw local status change event StatusChangeEvent [timestamp=1675255372016, current=UP, previous=STARTING]2023-02-01 20:42:52.018 INFO 15096 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_SPRING-CLOUD-CONFIG-CLIENT/DESKTOP-A5PHDVG:spring-cloud-config-client:3355: registering service...2023-02-01 20:42:52.033 INFO 15096 --- [ main] c.s.c.ConfigClientApplication : Started ConfigClientApplication in 10.224 seconds (JVM running for 10.92)2023-02-01 20:42:52.040 INFO 15096 --- [ionShutdownHook] o.s.c.n.e.s.EurekaServiceRegistry : Unregistering application SPRING-CLOUD-CONFIG-CLIENT with eureka with status DOWN2023-02-01 20:42:52.040 INFO 15096 --- [ionShutdownHook] com.netflix.discovery.DiscoveryClient : Saw local status change event StatusChangeEvent [timestamp=1675255372040, current=DOWN, previous=UP]2023-02-01 20:42:52.042 INFO 15096 --- [ionShutdownHook] com.netflix.discovery.DiscoveryClient : Shutting down DiscoveryClient ...2023-02-01 20:42:52.076 INFO 15096 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_SPRING-CLOUD-CONFIG-CLIENT/DESKTOP-A5PHDVG:spring-cloud-config-client:3355 - registration status: 2042023-02-01 20:42:52.077 INFO 15096 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_SPRING-CLOUD-CONFIG-CLIENT/DESKTOP-A5PHDVG:spring-cloud-config-client:3355: registering service...2023-02-01 20:42:52.080 INFO 15096 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_SPRING-CLOUD-CONFIG-CLIENT/DESKTOP-A5PHDVG:spring-cloud-config-client:3355 - registration status: 2042023-02-01 20:42:52.081 INFO 15096 --- [ionShutdownHook] com.netflix.discovery.DiscoveryClient : Unregistering ...2023-02-01 20:42:52.085 INFO 15096 --- [ionShutdownHook] com.netflix.discovery.DiscoveryClient : DiscoveryClient_SPRING-CLOUD-CONFIG-CLIENT/DESKTOP-A5PHDVG:spring-cloud-config-client:3355 - deregister status: 2002023-02-01 20:42:52.091 INFO 15096 --- [ionShutdownHook] com.netflix.discovery.DiscoveryClient : Completed shut down of DiscoveryClientDisconnected from the target VM, address: &apos;127.0.0.1:58233&apos;, transport: &apos;socket&apos;Process finished with exit code 0 其中有一句 Registering application SPRING-CLOUD-CONFIG-CLIENT with eureka with status UP， 查询资料，在这篇文章SpringCloud中Client向Eureka注册中心注册服务成功后不久就Unregistering（Unregistering application 服务名 with eureka with）中有提出解决办法 虽然 Config Client 子模块依赖的父模块中，pom文件已经引入了spring-boot-web 依赖，但是依旧要在 Config Client 子模块的pom文件上加上 spring-boot-web 依赖 12345&gt; &lt;dependency&gt;&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&gt; &lt;/dependency&gt;&gt; 再次启动，服务启动成功 12345678923-02-01 20:51:37.092 INFO 16848 --- [ main] c.n.discovery.InstanceInfoReplicator : InstanceInfoReplicator onDemand update allowed rate per min is 42023-02-01 20:51:37.098 INFO 16848 --- [ main] com.netflix.discovery.DiscoveryClient : Discovery Client initialized at timestamp 1675255897097 with initial instances count: 12023-02-01 20:51:37.100 INFO 16848 --- [ main] o.s.c.n.e.s.EurekaServiceRegistry : Registering application SPRING-CLOUD-CONFIG-CLIENT with eureka with status UP2023-02-01 20:51:37.100 INFO 16848 --- [ main] com.netflix.discovery.DiscoveryClient : Saw local status change event StatusChangeEvent [timestamp=1675255897100, current=UP, previous=STARTING]2023-02-01 20:51:37.103 INFO 16848 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_SPRING-CLOUD-CONFIG-CLIENT/DESKTOP-A5PHDVG:spring-cloud-config-client:3355: registering service...2023-02-01 20:51:37.138 INFO 16848 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 3355 (http) with context path &apos;&apos;2023-02-01 20:51:37.139 INFO 16848 --- [ main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 33552023-02-01 20:51:37.164 INFO 16848 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_SPRING-CLOUD-CONFIG-CLIENT/DESKTOP-A5PHDVG:spring-cloud-config-client:3355 - registration status: 2042023-02-01 20:51:38.241 INFO 16848 --- [ main] c.s.c.ConfigClientApplication : Started ConfigClientApplication in 12.417 seconds (JVM running for 13.157) Eureka注册中心 浏览器调用接口 那么，为什么Spring Cloud Config Client 的配置文件为什么要用 bootstrap.yml， 而不是 application ？ 这里有一篇文章有说明SpringCloud Config - client连接server的设置写在application.yml, 导致属性无法解析 Bootstrap.yml (bootstrap.properties) 是在application.yml (application.properties)之前加载的。它通常用于“使用SpringCloud Config Server时，应在bootstrap.yml中指定spring.application.name和spring.cloud.config.server.git.uri”以及一些加密/解密信息。 Spring Cloud会创建一个Bootstrap Context（由bootstrap.yml加载），作为Spring应用的Application Context（由application.yml加载）的父上下文。初始化的时候，Bootstrap Context负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的Environment。Bootstrap属性有高优先级，默认情况下，它们不会被本地配置覆盖。 例如，当使用SpringCloud Config时，通常从服务器加载“真正的”配置数据。为了获取URL（和其他连接配置，如密码等），您需要一个较早的或“bootstrap”配置。因此，您将配置服务器属性放在bootstrap.yml中，该属性用于加载实际配置数据（通常覆盖application.yml [如果存在]中的内容）。 补充： 在刚开始启动Spring Cloud Config Client 时，控制台提示： 1234567891011121314Description:No spring.config.import property has been definedAction:Add a spring.config.import=configserver: property to your configuration. If configuration is not required add spring.config.import=optional:configserver: instead. To disable this check, set spring.cloud.config.enabled=false or spring.cloud.config.import-check.enabled=false.Disconnected from the target VM, address: &apos;127.0.0.1:58966&apos;, transport: &apos;socket&apos;Process finished with exit code 1 stackoverflow上有篇文章No spring.config.import property has been defined中给出解决办法，在pom文件中加上依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;&lt;/dependency&gt;","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://yoursite.com/categories/编程语言/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"Spring Cloud Config","slug":"Spring-Cloud-Config","permalink":"http://yoursite.com/tags/Spring-Cloud-Config/"}]},{"title":"Arrays.asList()生成的对象不能执行add()的操作","slug":"Arrays-asList-生成的对象不能执行add-的操作","date":"2023-01-12T08:20:11.000Z","updated":"2023-01-13T01:43:04.478Z","comments":true,"path":"2023/01/12/Arrays-asList-生成的对象不能执行add-的操作/","link":"","permalink":"http://yoursite.com/2023/01/12/Arrays-asList-生成的对象不能执行add-的操作/","excerpt":"之前项目上，有使用 Arrays.asList() 创建一个List集合，并在后续的操作中使用之前创建的List集合继续 add() 添加元素。 12List&lt;String&gt; list = Arrays.asList(\"one\", \"two\", \"three\");list.add(\"five\"); 运行项目却在 list.add(\"five\"); 处报错： 1234Exception in thread &quot;main&quot; java.lang.UnsupportedOperationException at java.util.AbstractList.add(AbstractList.java:148) at java.util.AbstractList.add(AbstractList.java:108) ... 网上搜索资料得知， Arrays.asList() 生成的 ArrayList 对象是 Arrays 自己的内部类对象","text":"之前项目上，有使用 Arrays.asList() 创建一个List集合，并在后续的操作中使用之前创建的List集合继续 add() 添加元素。 12List&lt;String&gt; list = Arrays.asList(\"one\", \"two\", \"three\");list.add(\"five\"); 运行项目却在 list.add(\"five\"); 处报错： 1234Exception in thread &quot;main&quot; java.lang.UnsupportedOperationException at java.util.AbstractList.add(AbstractList.java:148) at java.util.AbstractList.add(AbstractList.java:108) ... 网上搜索资料得知， Arrays.asList() 生成的 ArrayList 对象是 Arrays 自己的内部类对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118/** * Returns a fixed-size list backed by the specified array. (Changes to * the returned list \"write through\" to the array.) This method acts * as bridge between array-based and collection-based APIs, in * combination with &#123;@link Collection#toArray&#125;. The returned list is * serializable and implements &#123;@link RandomAccess&#125;. * * &lt;p&gt;This method also provides a convenient way to create a fixed-size * list initialized to contain several elements: * &lt;pre&gt; * List&amp;lt;String&amp;gt; stooges = Arrays.asList(\"Larry\", \"Moe\", \"Curly\"); * &lt;/pre&gt; * * @param &lt;T&gt; the class of the objects in the array * @param a the array by which the list will be backed * @return a list view of the specified array */@SafeVarargs@SuppressWarnings(\"varargs\")public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a);&#125;/** * @serial include */private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable&#123; private static final long serialVersionUID = -2764017481108945198L; private final E[] a; ArrayList(E[] array) &#123; a = Objects.requireNonNull(array); &#125; @Override public int size() &#123; return a.length; &#125; @Override public Object[] toArray() &#123; return a.clone(); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T[] toArray(T[] a) &#123; int size = size(); if (a.length &lt; size) return Arrays.copyOf(this.a, size, (Class&lt;? extends T[]&gt;) a.getClass()); System.arraycopy(this.a, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; @Override public E get(int index) &#123; return a[index]; &#125; @Override public E set(int index, E element) &#123; E oldValue = a[index]; a[index] = element; return oldValue; &#125; @Override public int indexOf(Object o) &#123; E[] a = this.a; if (o == null) &#123; for (int i = 0; i &lt; a.length; i++) if (a[i] == null) return i; &#125; else &#123; for (int i = 0; i &lt; a.length; i++) if (o.equals(a[i])) return i; &#125; return -1; &#125; @Override public boolean contains(Object o) &#123; return indexOf(o) != -1; &#125; @Override public Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(a, Spliterator.ORDERED); &#125; @Override public void forEach(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); for (E e : a) &#123; action.accept(e); &#125; &#125; @Override public void replaceAll(UnaryOperator&lt;E&gt; operator) &#123; Objects.requireNonNull(operator); E[] a = this.a; for (int i = 0; i &lt; a.length; i++) &#123; a[i] = operator.apply(a[i]); &#125; &#125; @Override public void sort(Comparator&lt;? super E&gt; c) &#123; Arrays.sort(a, c); &#125;&#125; ArrayList 继承自 AbstractList，而 AbstractList 的 add() 方法抛出 UnsupportedOperationException 异常。 123456789101112131415/** * &#123;@inheritDoc&#125; * * &lt;p&gt;This implementation always throws an * &#123;@code UnsupportedOperationException&#125;. * * @throws UnsupportedOperationException &#123;@inheritDoc&#125; * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; * @throws IllegalArgumentException &#123;@inheritDoc&#125; * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */ public void add(int index, E element) &#123; throw new UnsupportedOperationException(); &#125; 当然，AbstractList 的 remove() 方法也是一样的 123456789101112/** * &#123;@inheritDoc&#125; * * &lt;p&gt;This implementation always throws an * &#123;@code UnsupportedOperationException&#125;. * * @throws UnsupportedOperationException &#123;@inheritDoc&#125; * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */ public E remove(int index) &#123; throw new UnsupportedOperationException(); &#125; 所以可以使用其他方式创建List集合对象 方法1： 1List&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList(\"a\", \"b\")); 方法2： 1List&lt;String&gt; list = Stream.of(\"str1\", \"str2\").collect(Collectors.toList());","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://yoursite.com/categories/编程语言/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"Arrays.asList","slug":"Arrays-asList","permalink":"http://yoursite.com/tags/Arrays-asList/"}]},{"title":"关于《软件设计师教程第5版》UML构件图两类接口描述错误的问题","slug":"关于《软件设计师教程第5版》UML构件图两类接口描述错误的问题","date":"2022-11-03T03:47:00.000Z","updated":"2022-11-03T03:48:14.347Z","comments":true,"path":"2022/11/03/关于《软件设计师教程第5版》UML构件图两类接口描述错误的问题/","link":"","permalink":"http://yoursite.com/2022/11/03/关于《软件设计师教程第5版》UML构件图两类接口描述错误的问题/","excerpt":"如图所示，在备考软件设计师时，有遇到关于 构件图 的题目，官方给的 -（ 是供接口，O- 是需接口，就像官方教程上展示的这样。但是发现有其他人说 -（ 是需接口，O- 是供接口。这就很懵圈了，然后我搜索国内的资料，也都是说： -（ 是需接口，O- 是供接口","text":"如图所示，在备考软件设计师时，有遇到关于 构件图 的题目，官方给的 -（ 是供接口，O- 是需接口，就像官方教程上展示的这样。但是发现有其他人说 -（ 是需接口，O- 是供接口。这就很懵圈了，然后我搜索国内的资料，也都是说： -（ 是需接口，O- 是供接口 # UML设计图10-构件图 # 【UML简明教程】接口 - Tim的资源站 我也去外网上搜索了一下，搜索到的资料也都显示的是： -（ 是需接口，O- 是供接口 # The different types of interfaces in UML diagram # What is Component Diagram? 从互联网上多数资料来看，正确的应该是 -（ 是需接口，O- 是供接口","categories":[{"name":"升级之路","slug":"升级之路","permalink":"http://yoursite.com/categories/升级之路/"}],"tags":[{"name":"软件设计","slug":"软件设计","permalink":"http://yoursite.com/tags/软件设计/"},{"name":"UML","slug":"UML","permalink":"http://yoursite.com/tags/UML/"},{"name":"构件图","slug":"构件图","permalink":"http://yoursite.com/tags/构件图/"}]},{"title":"根据JetBrains Fleet文档创建maven项目失败的解决办法","slug":"根据JetBrains-Fleet文档创建maven项目失败的解决办法","date":"2022-10-26T08:46:26.000Z","updated":"2022-10-26T09:24:04.204Z","comments":true,"path":"2022/10/26/根据JetBrains-Fleet文档创建maven项目失败的解决办法/","link":"","permalink":"http://yoursite.com/2022/10/26/根据JetBrains-Fleet文档创建maven项目失败的解决办法/","excerpt":"打算尝试一下Fleet编辑器，根据JetBrains Fleet文档创建maven项目. 首选确认本地机器上已经安装并配置了maven 按照文档提示，通过CTRL+ALT+T 打开 terminal 窗口，在编辑器的下方 粘贴并执行 mvn archetype:generate -DgroupId=com.mycompany.app -DartifactId=my-app -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false 创建失败，提下如下","text":"打算尝试一下Fleet编辑器，根据JetBrains Fleet文档创建maven项目. 首选确认本地机器上已经安装并配置了maven 按照文档提示，通过CTRL+ALT+T 打开 terminal 窗口，在编辑器的下方 粘贴并执行 mvn archetype:generate -DgroupId=com.mycompany.app -DartifactId=my-app -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false 创建失败，提下如下 然后google之，在stackoverflow上发现了这篇文章 https://stackoverflow.com/questions/16348459/error-the-goal-you-specified-requires-a-project-to-execute-but-there-is-no-pom 简而言之：必须用引号括起所有参数 于是重新修改了mvn命令并重新执行 mvn archetype:generate \"-DgroupId=com.mycompany.app\" \"-DartifactId=my-app\" \"-DarchetypeArtifactId=maven-archetype-quickstart\" \"-DarchetypeVersion=1.4\" \"-DinteractiveMode=false\" 于是maven项目创建成功","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://yoursite.com/categories/开发工具/"}],"tags":[{"name":"根据JetBrains","slug":"根据JetBrains","permalink":"http://yoursite.com/tags/根据JetBrains/"},{"name":"Fleet","slug":"Fleet","permalink":"http://yoursite.com/tags/Fleet/"},{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"}]},{"title":"MySQL根据出生日期计算当前年龄","slug":"MySQL根据出生日期计算当前年龄","date":"2022-10-21T06:03:18.000Z","updated":"2022-10-21T06:05:57.880Z","comments":true,"path":"2022/10/21/MySQL根据出生日期计算当前年龄/","link":"","permalink":"http://yoursite.com/2022/10/21/MySQL根据出生日期计算当前年龄/","excerpt":"假如人员的出生日期为 1994-10-01，首先用 MySQL 的 now() 函数获取当前系统日期，然后利用DATE_FORMAT() 函数计算出当前年龄。","text":"假如人员的出生日期为 1994-10-01，首先用 MySQL 的 now() 函数获取当前系统日期，然后利用DATE_FORMAT() 函数计算出当前年龄。 注意：DATE_FORMAT() 方法后面要加0 1select DATE_FORMAT(FROM_DAYS(DATEDIFF(now(), '1994-10-01')), '%Y')+0 as age 实践一下，当前系统时间为 2022-08-29 10:50:54 DATEDIFF() 函数返回两个日期之间的天数。 FROM_DAYS() 函数：给定一个天数N，并返回一个日期值。 DATE_FORMAT() 函数用于以不同的格式显示日期/时间数据。 使用FROM_DAYS()谨慎旧日期，它不打算使用与之前的公历(1582年)的到来值。 参考资料： https://www.tutorialspoint.com/calculate-age-based-on-date-of-birth-in-mysql","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"处理MySQL使用concat()函数时遇到null值的问题","slug":"处理MySQL使用concat-函数时遇到null值的问题","date":"2022-10-21T05:43:23.000Z","updated":"2023-02-21T07:19:13.550Z","comments":true,"path":"2022/10/21/处理MySQL使用concat-函数时遇到null值的问题/","link":"","permalink":"http://yoursite.com/2022/10/21/处理MySQL使用concat-函数时遇到null值的问题/","excerpt":"问题描述 使用CONCAT()拼接结果是，当CONCAT()函数中的一个参数为null，那么不管其他字符串是否有值，最后返回的拼接结果总是null，如下所示： 123456SELECT name, address, nationality, CONCAT('my name is ', name, ', to live in ', address, ', and i am from ', nationality) as strFROM `user2`","text":"问题描述 使用CONCAT()拼接结果是，当CONCAT()函数中的一个参数为null，那么不管其他字符串是否有值，最后返回的拼接结果总是null，如下所示： 123456SELECT name, address, nationality, CONCAT('my name is ', name, ', to live in ', address, ', and i am from ', nationality) as strFROM `user2` MySQL 官方文档有句话 解决办法 使用 COALESCE() 函数转换null值 123456SELECT name, address, nationality, CONCAT('my name is ', COALESCE(name, ''), ', to live in ', COALESCE(address, ''), ', and i am from ', COALESCE(nationality, '')) as strFROM `user2` 使用IFNULL() 函数转换null值 123456SELECT name, address, nationality, CONCAT('my name is ', ifnull(name, ''), ', to live in ', ifnull(address, ''), ', and i am from ', ifnull(nationality, '')) as strFROM `user2` 尝试使用CONCAT_WS() 函数拼接字符串 123456SELECT name, address, nationality, CONCAT_WS(',',name,address,nationality) as strFROM `user2` 参考资料： https://stackoverflow.com/questions/15741314/mysql-concat-returns-null-if-any-field-contain-null 12.8 String Functions and Operators 12.5 Flow Control Functions","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"货币的发行","slug":"货币的发行","date":"2022-07-25T07:06:15.000Z","updated":"2022-07-29T07:04:22.046Z","comments":true,"path":"2022/07/25/货币的发行/","link":"","permalink":"http://yoursite.com/2022/07/25/货币的发行/","excerpt":"中国共产党的货币实践有一个特点，就是货币本位十分灵活（当然也有革命条件艰苦缺乏贵金属的因素），从革命战争年代到改革开放以前长期实行的是一种“物资本位”。下面以长征时期的货币发行实践举例，题主大概可以见微知著，了解“物资本位”货币的发行、流通与回收","text":"中国共产党的货币实践有一个特点，就是货币本位十分灵活（当然也有革命条件艰苦缺乏贵金属的因素），从革命战争年代到改革开放以前长期实行的是一种“物资本位”。下面以长征时期的货币发行实践举例，题主大概可以见微知著，了解“物资本位”货币的发行、流通与回收 1935年1月7日，红军攻占遵义城。遵义是贵州省内仅次于贵阳的第二大城市，一向为黔北中心，各种土产集散地，汉、苗等族商旅云集之所，市场十分繁华，是红军长征以来所经过的第一座繁华的中等城市。 红军大部队进城时，群众已发动起来，“各种商店都已开门营业，百货日用品、食品到处都是，街上行人也很多，有赶街市的，有看热闹的，有做宣传的，还有高声叫卖麻糖的”。久困大山、长期作战的红军指战员，得到这么一个难得的休整机会，来到这么一个有大量东西可买的地方，也急需用经费购买生活、医疗等用品，以利今后的行军打仗。 但由于红军指战员随身携带的经费一部分或全部是苏维埃国家银行在中央苏区发行的苏维埃纸币，它们在白区无法流通，得不到当地百姓的认可。另一方面，当年遵义作为国民党政府的一个行署，管辖十来个县，自是军阀、官僚、地主、奸商相互勾结的地方，贵州军阀王家烈便在这里称雄一方。他在遵义开有烟馆、盐行，囤积了价值几十万元的食盐和大量烟土。当地缺盐，他一手操纵市场，以高价出售。其时猪肉才两角钱一斤，盐巴倒要四角钱一斤。许多老百姓因为买不起盐而患大脖子病。 苏维埃国家银行对上述情况进行了充分的估量，认为这种一面到处是商机、商业活动，一面群众严重缺盐而军阀囤积居奇的局面，有利于发行苏维埃钞票，主导市场，满足群众需要。他们把没收来的大量食盐和其他稀缺物资以低价卖给群众，规定只收苏维埃钞票，不收其他货币。而且一元苏维埃钞票可到兑换点换取一元二角现洋，或两元国民党的钞票。由于国家银行有充足的现金(银圆、金条等)和物资保证，发行的苏维埃钞票完全可以兑现，遵义城及附近驻有红军部队的城镇的群众和商家都乐于接纳、使用苏维埃钞票，红军指战员得以用手中的苏维埃币购买必要的物资。苏维埃钞票信誉盛极一时，市面也空前繁荣。为此，国家银行的工作人员在遵义度过了最为忙碌的10天。 由于无法在遵义建立稳固的根据地，红军决定撤离遵义。在红军撤离遵义前，为避免百姓蒙受损失或招来报复，苏维埃国家银行连夜组织回笼苏维埃币。这样，短短的十几天里，苏维埃国家银行完成了苏维埃币的发行、流通与回收，创造了一个奇迹。 国家银行在遵义发行、回笼苏维埃钞票的做法，既活跃了市场，保障了红军的供给，又维护了苏维埃钞票的信誉，维护了群众的利益，因而在当地留下了很好的影响，树立了共产党和红军的良好形象。对于当年少数还流散在群众手中的苏维埃钞票，1955年国家发行新的人民币时，还以1∶1的比价兑回了。 -- 以上来自 知乎 方亮 关于货币发行的问题，可能大多数人是不清楚的，但是不了解货币发行的原理，对于各种经济学现象就不能真正的理解。关于中国目前货币是如何发行的，这样发行的道理又是什么，本人做了以下研究和思考。 首先国内货币的发行，离不开中国人民银行（简称央行，是中华人民共和国的中央银行）。本人理解央行和现代企业运行的基本规则是相似的。企业的主要职责是赚取利润，而央行的主要职责就是通过控制市场中货币的数量，来实现物价稳定（即通货膨胀指标）、经济发展、充分就业、国际收支平衡（汇率指标）等目标。央行对外提供借款，需要设定利率和借款期限，到期收回借款，央行可以对外支付对价购买外汇、债券等资产，这些都是和企业的运行规则是相似的。 央行控制市场中货币数量的方法主要包括向商业银行购买外汇和提供贷款。其中提供贷款又可细分为MLF、PSL等公开市场操作投放和再贷款、再贴现投放。 首先要说明的央行向商业银行购买外汇。目前国际贸易中主要是以美元结算，因为美国的超级大国的国际地位，让美元成为类似于黄金的硬通货。正是因为美元作为国际结算的主要货币，所以国家需要储备美元资产。国内的对外贸易公司通过向国外出售商品赚取到了美元，将一部分需要兑换成人民币的美元出售给中国银行（国内一般都是出售给中国银行），央行再向商业银行购买这部分外汇。央行购买的外汇向国外换为其他资产，如下图所示。 央行购买外汇支付的是债券（即人民币），这里债券相当于借条，只不过因为央行的地位，这张借条有了在市场流通的价值，可以在市场中购买资产，所以也就不需要用这张借条向央行要求还资产了。（在这里要说明的是，央行对外支付的货币可以是纸质也可以是账户里的余额，两者是等价的。在现实生活中，纸质货币能满足大家的一些使用需求，所以央行需要投放和更换市场中的纸质货币，满足大家对纸质货币的使用需求。但市场中的货币，现金（M0)只占其中一小部分，货币大部分以银行存款的余额和其他形式存在，这里不做过多解释。）央行和商业银行的资产负债表如下图所示。 央行从商业银行手中买入资产，通过增加商业银行在央行账户的存款准备金为支付手段。商业银行可以在超出央行规定的存款准备金比例之外的资金支取，用于银行的对外贷款等业务，从而增加了货币在市场中的数量。 央行在向商业银行提供贷款中，央行增加债权资产和商业银行存款负债，商业银行增加负债和央行存款。央行向商业银行提供贷款同样增加了市场中货币的数量。 增加的货币数量，通过货币乘数，转化为真正的货币增量。（具体原理：假设甲有1000元的现金，存在商业银行A活期存款帐户。银行按照中央银行的要求，把其中10%（100元）交纳法定准备金，存入中央银行。剩下的900元可以全部贷出去，贷给乙。乙把这些钱再存入乙在B银行的帐户，B银行再交给中国人民银行90元，剩下的再贷出去。周而复始，理论上可以产生10000（1000/10%）元的活期存款。那么这个货币乘数就是10。10000元为真正增加的货币数量） 以上是央行控制市场中货币数量的方法，央行会根据市场是否缺少流动性，来调整其以上方法的使用力度，达到其想要实施的货币政策。 市场中货币数量的增加，在总商品数量不变的情况下，会引起商品价格的上升，货币总是追逐相对有些的商品引起价格的上升。因此当货币发行的速度，大于GDP的增长速度，那么就会带来通货膨胀。在通货膨胀的过程中，谁会受益呢？应该是能从价格上升中得到益处的人。通过努力，在这个过程中拥有较多具有保值功能的资产的人会受益。还有谁会受益呢，能够利用流动性宽裕的人，通过其良好的运作，可以在其中获益。 -- 以上来自 知乎 大峰哥","categories":[{"name":"兴趣使然","slug":"兴趣使然","permalink":"http://yoursite.com/categories/兴趣使然/"}],"tags":[{"name":"货币","slug":"货币","permalink":"http://yoursite.com/tags/货币/"}]},{"title":"Java抽象类和接口","slug":"Java抽象类和接口","date":"2020-07-08T05:36:47.000Z","updated":"2022-10-21T06:11:36.402Z","comments":true,"path":"2020/07/08/Java抽象类和接口/","link":"","permalink":"http://yoursite.com/2020/07/08/Java抽象类和接口/","excerpt":"先说对这两个概念的理解 我们先说抽象类，其实抽象类的设计理念是“is-a”关系，就是说它更关心的是被抽象的这些个对象是什么，比如说藏獒，贵宾，哈士奇，我们要给他们写抽象类，那抽象出来这个类就是狗狗类，无论什么品种的狗，都是狗狗。 再说说接口，接口的设计理念是“has-a”关系，它关心的能做什么，比如说你可以写一个接口，里面有吠()这个方法，再写一个接口，里面有跑()这个方法，那么你可以让狗狗类实现这两个方法，让狗狗拥有这两项功能。而你可以发现，人类，喵类也都可以实现整个跑这个接口来拥有这项功能。","text":"先说对这两个概念的理解 我们先说抽象类，其实抽象类的设计理念是“is-a”关系，就是说它更关心的是被抽象的这些个对象是什么，比如说藏獒，贵宾，哈士奇，我们要给他们写抽象类，那抽象出来这个类就是狗狗类，无论什么品种的狗，都是狗狗。 再说说接口，接口的设计理念是“has-a”关系，它关心的能做什么，比如说你可以写一个接口，里面有吠()这个方法，再写一个接口，里面有跑()这个方法，那么你可以让狗狗类实现这两个方法，让狗狗拥有这两项功能。而你可以发现，人类，喵类也都可以实现整个跑这个接口来拥有这项功能。 所以在java中，类的单继承多实现的概念就好理解了，狗狗只能继承狗狗这个类，不可能让它去继承人类或者喵类，但能实现n多个接口，跑、跳、吠、打滚。 在应用场景中，抽象类用于同类事物，而接口多是可以横跨很多个类。 他们有哪些具体区别呢？ 1）抽象类则可以包含普通方法，接口中的普通方法默认为抽象方法。 2）抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是 public static final 类型的，并且必须赋值，否则通不过编译。 3）接口不能包含构造器，抽象类可以包含构造器，抽象类里的构造器并不是用于创建对象，而是让其子类调用这些构造器来完成属于抽象类的初始化操作。 4）接口里不能包含初始化块，但抽象类里完全可以包含初始化块。 5）就是我们所说的单继承多实现了。 最后，送上我在一本书上看到的特别绕的三句话，接口可以继承接口，抽象类可以实现接口，抽象类可以继承具体类。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://yoursite.com/categories/编程语言/"}],"tags":[{"name":"抽象类","slug":"抽象类","permalink":"http://yoursite.com/tags/抽象类/"},{"name":"接口","slug":"接口","permalink":"http://yoursite.com/tags/接口/"}]},{"title":"MySQL事务","slug":"MySQL事务","date":"2020-04-26T02:38:32.000Z","updated":"2022-07-25T06:26:34.838Z","comments":true,"path":"2020/04/26/MySQL事务/","link":"","permalink":"http://yoursite.com/2020/04/26/MySQL事务/","excerpt":"MySQL数据库事务是一组原子性的SQL单元，事务内的语句要么全部执行成功，要么全部执行失败。 事务的四个特性 原子性（Atomicity） 事务必须是原子工作单元，事务中的操作要么全部执行成功，要么全部执行失败，不能只执行部分操作。 一致性 事务开始之前，数据库处于一致性的状态；事务结束后，数据库必须仍处于一致性状态。数据库一致性的定义是由用户负责的。例如，在银行转账中，用户可以定义转账前后两个账户金额之和保持不变。 隔离性 通常来说一个事务在修改时但还未提交，对其他事务是不可见的。 持久性 -一旦事务提交，则其所做的修改就会永久保存在数据库中。此时即使系统崩溃，修改的数据也不会丢失。","text":"MySQL数据库事务是一组原子性的SQL单元，事务内的语句要么全部执行成功，要么全部执行失败。 事务的四个特性 原子性（Atomicity） 事务必须是原子工作单元，事务中的操作要么全部执行成功，要么全部执行失败，不能只执行部分操作。 一致性 事务开始之前，数据库处于一致性的状态；事务结束后，数据库必须仍处于一致性状态。数据库一致性的定义是由用户负责的。例如，在银行转账中，用户可以定义转账前后两个账户金额之和保持不变。 隔离性 通常来说一个事务在修改时但还未提交，对其他事务是不可见的。 持久性 -一旦事务提交，则其所做的修改就会永久保存在数据库中。此时即使系统崩溃，修改的数据也不会丢失。 事务的脏读、不可重复读、幻读 脏读：事务 A 读取了事务 B 更新后的数据，但是事务 B 没有提交，然后事务 B 执行回滚操作，那么事务 A 读到的数据就是脏数据。 不可重复读：事务 A 进行多次读取操作，事务 B 在事务 A 多次读取的过程中执行更新操作并提交，提交后事务 A 读到的数据不一致。 幻读：事务 A 将数据库中所有学生的成绩由 A -&gt; B，此时事务 B 手动插入了一条成绩为 A 的记录，在事务 A 更改完毕后，发现还有一条记录没有修改，那么这种情况就叫做出现了幻读。 事务的隔离级别 读未提交(read uncommitted)、读已提交(read committed)、可重复读(repetable read) 和 串行化(serializable)。 读未提交：读未提交指的是一个事务在提交之前，它所做的修改就能够被其他事务所看到。 读已提交：读已提交指的是一个事务在提交之后，它所做的变更才能够让其他事务看到。 可重复读：可重复读指的是一个事务在执行的过程中，看到的数据是和启动时看到的数据是一致的。未提交的变更对其他事务不可见。 串行化：顾名思义是对于同一行记录，写会加写锁，读会加读锁。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 隔离级别由低到高是：读未提交 &lt; 读已提交 &lt; 可重复读 &lt; 串行化 MySQL 常见存储引擎的区别 通过SQL语句 SHOW ENGINES查看存储引擎 可以看到，InnoDB 是 MySQL 默认支持的存储引擎，支持事务、行级锁定和外键。 MyISAM 存储引擎的特点 在 5.1 版本之前，MyISAM 是 MySQL 的默认存储引擎，MyISAM 并发性比较差，使用的场景比较少，主要特点是 不支持事务操作，ACID 的特性也就不存在了，这一设计是为了性能和效率考虑的。 不支持外键操作，如果强行增加外键，MySQL 不会报错，只不过外键不起作用。 MyISAM 默认的锁粒度是表级锁，所以并发性能比较差，加锁比较快，锁冲突比较少，不太容易发生死锁的情况。 MyISAM 会在磁盘上存储三个文件，文件名和表名相同，扩展名分别是 .frm(存储表定义)、.MYD(MYData,存储数据)、MYI(MyIndex,存储索引)。这里需要特别注意的是 MyISAM 只缓存索引文件，并不缓存数据文件。 MyISAM 支持的索引类型有 全局索引(Full-Text)、B-Tree 索引、R-Tree 索引 Full-Text 索引：它的出现是为了解决针对文本的模糊查询效率较低的问题。 B-Tree 索引：所有的索引节点都按照平衡树的数据结构来存储，所有的索引数据节点都在叶节点 R-Tree索引：它的存储方式和 B-Tree 索引有一些区别，主要设计用于存储空间和多维数据的字段做索引,目前的 MySQL 版本仅支持 geometry 类型的字段作索引，相对于 BTREE，RTREE 的优势在于范围查找。 数据库所在主机如果宕机，MyISAM 的数据文件容易损坏，而且难以恢复。 增删改查性能方面：SELECT 性能较高，适用于查询较多的情况 InnoDB 存储引擎的特点 自从 MySQL 5.1 之后，默认的存储引擎变成了 InnoDB 存储引擎，相对于 MyISAM，InnoDB 存储引擎有了较大的改变，它的主要特点是 支持事务操作，具有事务 ACID 隔离特性，默认的隔离级别是可重复读(repetable-read)、通过MVCC（并发版本控制）来实现的。能够解决脏读和不可重复读的问题。 InnoDB 支持外键操作。 InnoDB 默认的锁粒度行级锁，并发性能比较好，会发生死锁的情况。 和 MyISAM 一样的是，InnoDB 存储引擎也有 .frm文件存储表结构 定义，但是不同的是，InnoDB 的表数据与索引数据是存储在一起的，都位于 B+ 数的叶子节点上，而 MyISAM 的表数据和索引数据是分开的。 InnoDB 有安全的日志文件，这个日志文件用于恢复因数据库崩溃或其他情况导致的数据丢失问题，保证数据的一致性。 InnoDB 和 MyISAM 支持的索引类型相同，但具体实现因为文件结构的不同有很大差异。 增删改查性能方面，如果执行大量的增删改操作，推荐使用 InnoDB 存储引擎，它在删除操作时是对行删除，不会重建表。 MyISAM 和 InnoDB 存储引擎的对比 锁粒度方面：由于锁粒度不同，InnoDB 比 MyISAM 支持更高的并发；InnoDB 的锁粒度为行锁、MyISAM 的锁粒度为表锁、行锁需要对每一行进行加锁，所以锁的开销更大，但是能解决脏读和不可重复读的问题，相对来说也更容易发生死锁 可恢复性上：由于 InnoDB 是有事务日志的，所以在产生由于数据库崩溃等条件后，可以根据日志文件进行恢复。而 MyISAM 则没有事务日志。 查询性能上：MyISAM 要优于 InnoDB，因为 InnoDB 在查询过程中，是需要维护数据缓存，而且查询过程是先定位到行所在的数据块，然后在从数据块中定位到要查找的行；而 MyISAM 可以直接定位到数据所在的内存地址，可以直接找到数据。 表结构文件上：MyISAM 的表结构文件包括：.frm(表结构定义),.MYI(索引),.MYD(数据)；而 InnoDB 的表数据文件为:.ibd和.frm(表结构定义)； 文章来自Java建设者","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"http://yoursite.com/tags/事务/"}]},{"title":"Java多线程","slug":"Java多线程","date":"2020-04-14T05:18:42.000Z","updated":"2022-10-21T06:11:28.136Z","comments":true,"path":"2020/04/14/Java多线程/","link":"","permalink":"http://yoursite.com/2020/04/14/Java多线程/","excerpt":"Java 给多线程编程提供了内置的支持。 一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。 多线程是多任务的一种特别的形式，但多线程使用了更小的资源开销。 这里定义和线程相关的另一个术语 - 进程：一个进程包括由操作系统分配的内存空间，包含一个或多个线程。一个线程不能独立的存在，它必须是进程的一部分。一个进程一直运行，直到所有的非守护线程都结束运行后才能结束。 多线程能满足程序员编写高效率的程序来达到充分利用 CPU 的目的。","text":"Java 给多线程编程提供了内置的支持。 一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。 多线程是多任务的一种特别的形式，但多线程使用了更小的资源开销。 这里定义和线程相关的另一个术语 - 进程：一个进程包括由操作系统分配的内存空间，包含一个或多个线程。一个线程不能独立的存在，它必须是进程的一部分。一个进程一直运行，直到所有的非守护线程都结束运行后才能结束。 多线程能满足程序员编写高效率的程序来达到充分利用 CPU 的目的。 线程和进程的区别 线程是进程的子集，一个进程可以有很多线程，每条线程并行执行不同的任务。不同的进程使用不同的内存空间，而所有的线程共享一片相同的内存空间。别把它和栈内存搞混，每个线程都拥有单独的栈内存来存储本地数据。 创建线程有哪几种方式？分别有什么优缺点？ 创建线程 继承Thread类，重写run()方法； 实现Runnable接口，实现run()方法，并将该实现类作为参数传入Thread构造器。 实现Callable接口，重写call()方法，并包装成FutureTask对象，再作为参数传入Thread构造器。 继承Thread类优缺点 优点是编码简单，缺点是不能再继承其他的类，功能单一。 实现Runnable接口优缺点 优点是可以继承其他类，避免单继承的局限性；适合多个相同程序代码的线程共享一个资源，实现解耦操作，代码和线程独立。缺点是实现相对复杂。 实现Callable接口优缺点 优点是相比方式二可以获取返回值，缺点是实现复杂。 线程的状态 new（新建）：线程刚刚被创建，但是并未启动，还没有调用start方法。 Runnable（可运行）：线程可以在Java虚拟机中执行的状态，但是这个“执行”，不一定是真的运行，也可能是在等待CPU资源。所以在网上，有人把这个状态区分为READY和RUNNING两个，一个表示的start了，资源一到位随时可以执行，另一个表示真正的执行中。 Blocked（锁阻塞）：当一个线程试图获取一个锁对象，而该对象被其他的线程持有，则该线程进入Blocked状态；比较经典的就是synchronized关键字，这个关键字修饰的代码块或者方法，均需要获取到对应的锁，在未获取之前，其线程的状态就一直为BLOCKED，当该线程持有锁时，该线程将变成Runnable状态。如果线程长时间处于这种状态下，我们就要当心，看看是否出现死锁的问题了。 Waiting（无限等待）：一个线程在等待另一个线程执行动作是，该线程进入Waiting状态。进入这个状态后是不能自动唤醒的，必须等待另一个线程调用notify或者notifyAll方法才能够唤醒。 Timed Waiting（计时等待）：同waiting状态，有几个方法有超时参数，调用他们将进入Timed Waiting状态。如： Object.wait() Thread.join() Thread.sleep LockSupport.park() 这一状态将一直保持到超时期满或者收到唤醒通知。 THRMINATED（死亡状态）：因为run方法正常退出而死亡，或者因为没有捕获的异常终止了run方法而死亡。 volatile关键字 保证被修饰的变量对所有线程可见，在一个线程修改一个变量的值后，新值对其他线程是可以立即获取的。 禁止指令重排序，被修饰的变量不会被缓存在寄存器中或者对其他处理器不可见的地方，因此在读取volatile修饰的变量时总是会返回最新写入的值。 不会执行加锁操作，不会导致线程阻塞，主要适用于一个变量被多个线程共享，多个线程均可对这个变量执行赋值或读取的操作， volatile可以严格保证变量的单次读写操作的原子性，但不能保证像i++ 这种操作的原子性，因为i++ 在本质上是读、写两次操作。 synchronized关键字 用于为Java对象、方法、代码块提供线程安全的操作，属于排它的悲观锁，也属于可重入锁。 被synchronzied修饰的方法和代码块在同一时刻只能有一个线程访问，其他线程只能等待当前线程释放资源后才能访问。 Java中的每个对象都有一个monitor监视器对象，加锁就是在竞争monitor，对代码块加锁是通过在前后分别加上monitorenter和monitorexit指令实现的，对方是否加锁是通过一个标记位来判断的。 线程池是什么？为什么需要线程池？ 在生产中为每一个任务创建一个线程存在一些缺陷，如果无限制地大量创建线程会消耗很多资源，影响系统稳定性和性能，产生内存溢出等问题。 线程池是管理一组同构工作线程的资源池，线程池与工作队列密切相关，工作队列中保存了所有需要等待执行的任务。工作线程的任务很简单，从工作队列获取任务，执行任务，返回线程池并等待下一次任务。 线程池通过重用现有的线程，可以在处理多个请求时分摊线程在创建和撤销过程中的开销，另一个好处是当请求到达时工作线程通常已经存在，不会出现等待线程而延迟的任务的执行，提高了响应性。通过调整线程池的大小，可以创建足够多的线程保持处理器处于忙碌状态，同时还可以防止线程过多导致内存资源耗尽。 创建线程池时，ThreadPoolExecutor构造器中都有哪些参数以及各自的含义 corePoolSize： 线程池核心大小，即在没有任务执行时线程池的大小，并且只有在工作队列满了的情况下才会创建超出这个数量的线程。 maximumPoolSize： 线程池最大大小，表示可同时活动的线程数量的上限。 keepAliveTime：存活时间，如果某个线程的空闲时间超过了存活时间，那么将被标记为可回收的，并且当线程池的当前大小超过基本大小时，这个线程将被终止。 unit： 存活时间的单位，可选的参数为TimeUnit枚举中的几个静态变量： NANOSECONDS、MICROSECONDS、MILLISECONDS、SECONDS。 workQueue： 线程池所使用的阻塞队列。 thread factory：线程池使用的创建线程工厂方法，可省略，将使用默认工厂。 handler：所用的拒绝执行处理策略，可省略，将使用默认拒绝执行策略。 创建线程池的方法有哪些？ 可以通过Executors的静态工厂方法创建线程池，内部通过重载ThreadExecutorPool不同的构造器创建线程池。 newFixedThreadPool，创建一个固定长度的线程池，每当提交一个任务就创建一个线程，直到达到线程池的最大数量，这时线程池的规模将不再变化(如果某个线程由于发生了未预期的异常而结束，那么线程池会补充一个新的线程)。将线程池的核心大小和最大大小都设置为参数中指定的值，创建的线程不会超时，使用LinkedBlockingQueue。 newCachedThreadPool，创建一个可缓存的线程池，如果线程池的当前规模超过了处理器需求，那么将回收空闲的线程，而当需求增加时，可以添加新的线程，线程池的规模不存在任何限制。将线程池的最大大小设置为Integer.MAX_VALUE，而将核心大小设置为0，并将超时设为1分钟，使用SynchronousQueue，这种方法创建出的线程池可被无限扩展，并当需求降低时自动收缩。 newSingleThreadExecutor，一个单线程的Executor，创建单个工作者线程来执行任务，如果这个线程异常结束，会创建另一个线程来代替。确保依照任务在队列中的顺序来串行执行。将核心线程和最大线程数都设置为1，使用LinkedBlockingQueue。 newScheduledThreadPool，创建一个固定长度的线程池，而且以延迟或定时的方式来执行任务，类似于Timer，使用DelayedWorkQueue。 线程池的工作原理 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。即使队列里面有任务，线程池也不会马上执行它们。 通过 execute(Runnable command)方法被添加到线程池，任务就是一个 Runnable类型的对象，任务的执行方法就是Runnable类型对象的run()方法。 如果workerCount 小于corePoolSize，那么创建并启动一个线程执行新提交的任务。如果workerCount大于等于corePoolSize，且线程池内的阻塞队列未满，那么将这个任务放入队列。如果workerCount大于等于corePoolSize，且阻塞队列已满，若满足workerCount小于maximumPoolSize,那么还是要创建并启动一个线程执行新提交的任务。若阻塞队列已满，并且workerCount大于等于maximumPoolSize，则根据 handler所指定的策略来处理此任务，默认的处理方式直接抛出异常。也就是处理任务的优先级为： 核心线程corePoolSize、任务队列workQueue、最大线程maximumPoolSize，如果三者都满了，使用handler处理被拒绝的任务。 当一个线程完成任务时，它会从队列中取下一个任务来执行。 当一个线程没有任务可执行，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于corePoolSize时，那么这个线程会被停用掉，所以线程池的所有任务完成后，它最终会收缩到corePoolSize的大小。 start和run方法的区别 start方法用于启动线程，真正实现了多线程，调用了start方法后，会在后台创建一个新的线程来执行，不需要等待run方法执行完毕就可以继续执行其他代码。调用start方法时，该线程处于就绪状态，并没有开始运行。 run方法也叫做线程体，包含了要执行的线程的逻辑代码，在调用run方法并没有创建新的线程，而是直接运行run方法中的代码。 References https://blog.csdn.net/qq_41112238/article/details/105074636 https://baijiahao.baidu.com/s?id=1655501582187466001&amp;wfr=spider&amp;for=pc https://www.jianshu.com/p/ec94ed32895f","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://yoursite.com/categories/编程语言/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"线程","slug":"线程","permalink":"http://yoursite.com/tags/线程/"}]},{"title":"面试官邪魅一笑：MySQL千万级别大表，你要如何优化？","slug":"面试官邪魅一笑：MySQL千万级别大表，你要如何优化？","date":"2020-04-09T01:13:07.000Z","updated":"2022-10-21T05:58:07.480Z","comments":true,"path":"2020/04/09/面试官邪魅一笑：MySQL千万级别大表，你要如何优化？/","link":"","permalink":"http://yoursite.com/2020/04/09/面试官邪魅一笑：MySQL千万级别大表，你要如何优化？/","excerpt":"当MySQL单表记录数过大时，增删改查性能都会急剧下降，可以参考以下步骤来优化：","text":"当MySQL单表记录数过大时，增删改查性能都会急剧下降，可以参考以下步骤来优化： 单表优化 除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度，一般以整型值为主的表在千万级以下，字符串为主的表在五百万以下是没有太大问题的。而事实上很多时候MySQL单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量： 字段 尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED VARCHAR的长度只分配真正需要的空间 使用枚举或整数代替字符串类型 尽量使用TIMESTAMP而非DATETIME， 单表不要有太多字段，建议在20以内 避免使用NULL字段，很难查询优化且占用额外索引空间 用整型来存IP 索引 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描 值分布很稀少的字段不适合建索引，例如\"性别\"这种只有两三个值的字段 字符字段只建前缀索引 字符字段最好不要做主键 不用外键，由程序保证约束 尽量不用UNIQUE，由程序保证约束 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引 查询SQL 可通过开启慢查询日志来找出较慢的SQL 不做列运算：SELECT id WHERE age + 1 = 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边 sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库 不用`SELECT *`` OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内 不用函数和触发器，在应用程序实现 避免%xxx式查询 少用JOIN 使用同类型进行比较，比如用'123'和'123'比，123和123比 尽量避免在WHERE子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描 对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5 列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大 引擎 目前广泛使用的是MyISAM和InnoDB两种引擎： MyISAM MyISAM引擎是MySQL 5.1及之前版本的默认引擎，它的特点是： 不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁 不支持事务 不支持外键 不支持崩溃后的安全恢复 在表有读取查询的同时，支持往表中插入新纪录 支持BLOB和TEXT的前500个字符索引，支持全文索引 支持延迟更新索引，极大提升写入性能 对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用 InnoDB InnoDB在MySQL 5.5后成为默认索引，它的特点是： 支持行锁，采用MVCC来支持高并发 支持事务 支持外键 支持崩溃后的安全恢复 不支持全文索引 总体来讲，MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表 系统调优参数 可以使用下面几个工具来做基准测试： sysbench：一个模块化，跨平台以及多线程的性能测试工具 iibench-mysql：基于 Java 的 MySQL/Percona/MariaDB 索引进行插入性能测试工具 tpcc-mysql：Percona开发的TPC-C测试工具 具体的调优参数内容较多，具体可参考官方文档，这里介绍一些比较重要的参数： back_log：back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。可以从默认的50升至500 wait_timeout：数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的8小时减到半小时 max_user_connection: 最大连接数，默认为0无上限，最好设一个合理上限 thread_concurrency：并发线程数，设为CPU核数的两倍 skip_name_resolve：禁止对外部连接进行DNS解析，消除DNS解析时间，但需要所有远程主机用IP访问 key_buffer_size：索引块的缓存大小，增加会提升索引处理速度，对MyISAM表性能影响最大。对于内存4G左右，可设为256M或384M，通过查询show status like 'key_read%'，保证key_reads / key_read_requests在0.1%以下最好 innodb_buffer_pool_size：缓存数据块和索引块，对InnoDB表性能影响最大。通过查询show status like 'Innodb_buffer_pool_read%'，保证(Innodb_buffer_pool_read_requests – Innodb_buffer_pool_reads) / Innodb_buffer_pool_read_requests越高越好 innodb_additional_mem_pool_size：InnoDB存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL会记录Warning信息到数据库的错误日志中，这时就需要该调整这个参数大小 innodb_log_buffer_size：InnoDB存储引擎的事务日志所使用的缓冲区，一般来说不建议超过32MB query_cache_size：缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。当某个表的数据有任何任何变化，都会导致所有引用了该表的select语句在Query Cache中的缓存数据失效。所以，当我们的数据变化非常频繁的情况下，使用Query Cache可能会得不偿失。根据命中率(Qcache_hits/(Qcache_hits+Qcache_inserts)*100))进行调整，一般不建议太大，256MB可能已经差不多了，大型的配置型静态数据可适当调大. 可以通过命令show status like 'Qcache_%'查看目前系统Query catch使用大小 read_buffer_size：MySql读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小提高其性能 sort_buffer_size：MySql执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。如果不能，可以尝试增加sort_buffer_size变量的大小 read_rnd_buffer_size：MySql的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。 record_buffer：每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值 thread_cache_size：保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的 table_cache：类似于thread_cache_size，但用来缓存表文件，对InnoDB效果不大，主要用于MyISAM 升级硬件 Scale up，这个不多说了，根据MySQL是CPU密集型还是I/O密集型，通过提升CPU和内存、使用SSD，都能显著提升MySQL性能 读写分离 也是目前常用的优化，从库读主库写，一般不要采用双主或多主引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离 缓存 缓存可以发生在这些层次： MySQL内部：在系统调优参数介绍了相关设置 数据访问层：比如MyBatis针对SQL语句做缓存，而Hibernate可以精确到单个记录，这里缓存的对象主要是持久化对象Persistence Object 应用服务层：这里可以通过编程手段对缓存做到更精准的控制和更多的实现策略，这里缓存的对象是数据传输对象Data Transfer Object Web层：针对web页面做缓存 浏览器客户端：用户端的缓存 可以根据实际情况在一个层次或多个层次结合加入缓存。这里重点介绍下服务层的缓存实现，目前主要有两种方式： 直写式（Write Through）：在数据写入数据库后，同时更新缓存，维持数据库与缓存的一致性。这也是当前大多数应用缓存框架如Spring Cache的工作方式。这种实现非常简单，同步好，但效率一般。 回写式（Write Back）：当有数据要写入数据库时，只会更新缓存，然后异步批量的将缓存数据同步到数据库上。这种实现比较复杂，需要较多的应用逻辑，同时可能会产生数据库与缓存的不同步，但效率非常高。 表分区 MySQL在5.1版引入的分区是一种简单的水平拆分，用户需要在建表的时候加上分区参数，对应用是透明的无需修改代码。 对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成，实现分区的代码实际上是通过对一组底层表的对象封装，但对SQL层来说是一个完全封装底层的黑盒子。MySQL实现分区的方式也意味着索引也是按照分区的子表定义，没有全局索引。 用户的SQL语句是需要针对分区表做优化，SQL条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，可以通过EXPLAIN PARTITIONS来查看某条SQL语句会落在那些分区上，从而进行SQL优化，如下图5条记录落在两个分区上： 1234567mysql&gt; explain partitions select count(1) from user_partition where id in (1,2,3,4,5);+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+| 1 | SIMPLE | user_partition | p1,p4 | range | PRIMARY | PRIMARY | 8 | NULL | 5 | Using where; Using index |+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+1row in set (0.00 sec) 分区的好处是： 可以让单表存储更多的数据 分区表的数据更容易维护，可以通过清楚整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作 部分查询能够从查询条件确定只落在少数分区上，速度会很快 分区表的数据还可以分布在不同的物理设备上，从而搞笑利用多个硬件设备 可以使用分区表赖避免某些特殊瓶颈，例如InnoDB单个索引的互斥访问、ext3文件系统的inode锁竞争 可以备份和恢复单个分区 分区的限制和缺点： 一个表最多只能有1024个分区 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来 分区表无法使用外键约束 NULL值会使分区过滤无效 所有分区必须使用相同的存储引擎 分区的类型： RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区 LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择 HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL中有效的、产生非负整数值的任何表达式 KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值 分区适合的场景有： 最适合的场景数据的时间序列性比较强，则可以按时间来分区，如下所示： 1234567891011121314CREATE TABLE members ( firstname VARCHAR(25) NOT NULL, lastname VARCHAR(25) NOT NULL, username VARCHAR(16) NOT NULL, email VARCHAR(35), joined DATE NOT NULL)PARTITION BY RANGE( YEAR(joined) ) ( PARTITION p0 VALUES LESS THAN (1960), PARTITION p1 VALUES LESS THAN (1970), PARTITION p2 VALUES LESS THAN (1980), PARTITION p3 VALUES LESS THAN (1990), PARTITION p4 VALUES LESS THAN MAXVALUE); 查询时加上时间范围条件效率会非常高，同时对于不需要的历史数据能很容的批量删除。 如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会都缓存在内存中，查询时只访问一个很小的分区表，能够有效使用索引和缓存 另外MySQL有一种早期的简单的分区实现 - 合并表（merge table），限制较多且缺乏优化，不建议使用，应该用新的分区机制来替代 垂直拆分 垂直分库是根据数据库里面的数据表的相关性进行拆分，比如：一个数据库里面既存在用户数据，又存在订单数据，那么垂直拆分可以把用户数据放到用户库、把订单数据放到订单库。垂直分表是对数据表进行垂直拆分的一种方式，常见的是把一个多字段的大表按常用字段和非常用字段进行拆分，每个表里面的数据记录数一般情况下是相同的，只是字段不一样，使用主键关联 比如原始的用户表是： 垂直拆分后是： 垂直拆分的优点是： 可以使得行数据变小，一个数据块(Block)就能存放更多的数据，在查询时就会减少I/O次数(每次查询时读取的Block 就少) 可以达到最大化利用Cache的目的，具体在垂直拆分的时候可以将不常变的字段放一起，将经常改变的放一起 数据维护简单 缺点是： 主键出现冗余，需要管理冗余列 会引起表连接JOIN操作（增加CPU开销）可以通过在业务服务器上进行join来减少数据库压力 依然存在单表数据量过大的问题（需要水平拆分） 事务处理复杂 水平拆分 概述 水平拆分是通过某种策略将数据分片来存储，分库内分表和分库两部分，每片数据会分散到不同的MySQL表或库，达到分布式的效果，能够支持非常大的数据量。前面的表分区本质上也是一种特殊的库内分表 库内分表，仅仅是单纯的解决了单一表数据过大的问题，由于没有把表的数据分布到不同的机器上，因此对于减轻MySQL服务器的压力来说，并没有太大的作用，大家还是竞争同一个物理机上的IO、CPU、网络，这个就要通过分库来解决 前面垂直拆分的用户表如果进行水平拆分，结果是： 实际情况中往往会是垂直拆分和水平拆分的结合，即将Users_A_M和Users_N_Z再拆成Users和UserExtras，这样一共四张表 水平拆分的优点是: 不存在单库大数据和高并发的性能瓶颈 应用端改造较少 提高了系统的稳定性和负载能力 缺点是： 分片事务一致性难以解决 跨节点Join性能差，逻辑复杂 数据多次扩展难度跟维护量极大 分片原则 能不分就不分，参考单表优化 分片数量尽量少，分片尽量均匀分布在多个数据结点上，因为一个查询SQL跨分片越多，则总体性能越差，虽然要好于所有数据在一个分片的结果，只在必要的时候进行扩容，增加分片数量 分片规则需要慎重选择做好提前规划，分片规则的选择，需要考虑数据的增长模式，数据的访问模式，分片关联性问题，以及分片扩容问题，最近的分片策略为范围分片，枚举分片，一致性Hash分片，这几种分片都有利于扩容 尽量不要在一个事务中的SQL跨越多个分片，分布式事务一直是个不好处理的问题 查询条件尽量优化，尽量避免Select * 的方式，大量数据结果集下，会消耗大量带宽和CPU资源，查询尽量避免返回大量结果集，并且尽量为频繁使用的查询语句建立索引。 通过数据冗余和表分区赖降低跨库Join的可能 这里特别强调一下分片规则的选择问题，如果某个表的数据有明显的时间特征，比如订单、交易记录等，则他们通常比较合适用时间范围分片，因为具有时效性的数据，我们往往关注其近期的数据，查询条件中往往带有时间字段进行过滤，比较好的方案是，当前活跃的数据，采用跨度比较短的时间段进行分片，而历史性的数据，则采用比较长的跨度存储。 总体上来说，分片的选择是取决于最频繁的查询SQL的条件，因为不带任何Where语句的查询SQL，会遍历所有的分片，性能相对最差，因此这种SQL越多，对系统的影响越大，所以我们要尽量避免这种SQL的产生。 解决方案 由于水平拆分牵涉的逻辑比较复杂，当前也有了不少比较成熟的解决方案。这些方案分为两大类：客户端架构和代理架构。 客户端架构 通过修改数据访问层，如JDBC、Data Source、MyBatis，通过配置来管理多个数据源，直连数据库，并在模块内完成数据的分片整合，一般以Jar包的方式呈现 这是一个客户端架构的例子： 可以看到分片的实现是和应用服务器在一起的，通过修改Spring JDBC层来实现 客户端架构的优点是： 应用直连数据库，降低外围系统依赖所带来的宕机风险 集成成本低，无需额外运维的组件 缺点是： 限于只能在数据库访问层上做文章，扩展性一般，对于比较复杂的系统可能会力不从心 将分片逻辑的压力放在应用服务器上，造成额外风险 代理架构 通过独立的中间件来统一管理所有数据源和数据分片整合，后端数据库集群对前端应用程序透明，需要独立部署和运维代理组件 这是一个代理架构的例子： 代理组件为了分流和防止单点，一般以集群形式存在，同时可能需要Zookeeper之类的服务组件来管理 代理架构的优点是： 能够处理非常复杂的需求，不受数据库访问层原来实现的限制，扩展性强 对于应用服务器透明且没有增加任何额外负载 缺点是： 需部署和运维独立的代理中间件，成本高 应用需经过代理来连接数据库，网络上多了一跳，性能有损失且有额外风险。 文章转自 小哈学Java","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"},{"name":"优化","slug":"优化","permalink":"http://yoursite.com/tags/优化/"}]},{"title":"vsftpd配置文件详解","slug":"vsftpd配置文件详解","date":"2020-04-02T01:31:10.000Z","updated":"2022-10-21T06:09:06.229Z","comments":true,"path":"2020/04/02/vsftpd配置文件详解/","link":"","permalink":"http://yoursite.com/2020/04/02/vsftpd配置文件详解/","excerpt":"yum安装的vsftpd配置文件如下： 1vim /etc/vsftpd/vsftpd.conf 1）以“#”字符开始的行是注释行。每一行为一个选项设置，格式为“option=value”，注意“=”号两边不能留空白符。 2）除了这个主配置文件外，还可以给特定用户设定个人配置文件","text":"yum安装的vsftpd配置文件如下： 1vim /etc/vsftpd/vsftpd.conf 1）以“#”字符开始的行是注释行。每一行为一个选项设置，格式为“option=value”，注意“=”号两边不能留空白符。 2）除了这个主配置文件外，还可以给特定用户设定个人配置文件 1.与建立FTP链接相关的选项 1.1.监听地址与控制端口 123456789101112listen_address=[IP] # 提供ftp服务的主机IP，单IP主机，不需要使用，多IP主机默认监听所有IP地址。在VSFTPD使用单独(standalone)模式下有效。listen_port=[port] # 提供ftp服务的控制端口号，默认值为21。此选项在standalone模式下生效。port_enable=YES # 是否启用ftp主动模式，默认为YES。如果要在数据连接时取消PORT主动模式时，改为NOconnetc_from_port_20=NO # 以port主动模式进行数据传输时是否使用20端口，默认为NO不使用。但RHEL自带的vsftpd.conf文件中此参数设为YES。ftp_data_port=[port] # 指定ftp数据传输端口值，默认为20。此参数用于主动模式。port_promiscuous=NO # 取消PORT安全检查，默认为NO不取消检查。该检查确保外出的数据只能连接到客户端上。不建议打开pasv_enable=YES # 允许数据传输时使用PASV被动模式。默认为YES允许被动模式pasv_min_port=[minport]pasv_max_port=[maxport] # 设定在PASV被动模式下，建立数据传输所可以使用port范围的下界和上界，默认为0不限制。 # 把端口范围设在比较高的一段范围内，比如50000-60000，将有助于安全性的提高。pasv_promiscuous=NO # 是否关闭PASV模式的安全检查，默认值为NO不关闭。该检查确保数据连接和控制连接是来自同一个IP地址。不建议打开，此选项唯一合理的用法是存在于由安全隧道方案构成的组织中。pasv_address=[IP] # 此选项为一个数字IP地址，作为PASV命令的响应。默认值为none，即地址是从呼入的连接套接字(incomingconnectdsocket)中获取。 1.2.关于ftp服务的ASCII模式 默认情况下，VSFTPD使用二进制传输数据，禁止使用ASCII传输模式。 如果FTP客户端使用ascii命令，指明要使用ASCII模式，VSFTPD表面上接受了ascii命令，但在实际传输文件时，还是使用二进制方式，就会出现乱码文件 12ascii_upload_enable=NO #控制是否允许使用ascii模式上传文件，默认为NO不允许。ascii_download_enable=NO # 控制是否允许使用ascii模式下载文件，默认为NO不允许。 2.关于性能与负载控制 1234567891011idle_session_timeout=60 # 设置用户会话的空闲中断时间，单位为秒，默认值为300。data_connection_timeout=120 # 设置空闲的数据连接的中断时间。默认值为300秒。accept_timeout=60 # 接受建立联机的超时设定，单位为秒。默认值为60。connect_timeout=60 # 响应PORT方式的数据联机的超时设定，单位为秒。默认值为60。 # 以上两个选项针对客户端的，将使客户端空闲1分钟后自动中断连接，并在中断1分钟后自动激活连接。max_clients=200 # 指明服务器总的客户并发连接数为200，默认值为0，表示不限最大连接数。此参数在使用standalone模式下有效max_per_ip=3 # 指明每个IP地址的并发连接数，默认值为0不限制。该设置会影响到象网际快车这类的多进程下载软件。此参数在使用standalone模式下有效local_max_rate=50000 # 设置本地用户的最大传输速率限制（50kbytes/sec），以Bytes/s为单位。默认0不限制。此选项可以为指定用户单独设置anon_max_rate=30000 # 设定匿名用户的最大数据传输速度value，以Bytes/s为单位。默认0不限制pasv_min_port=50000 # 设置被动模式客户端连接时的端口范围，默认为0不限制pasv_max_port=60000 3.用户选项 VSFTPD的用户分为三类：匿名用户、本地用户（localuser）以及虚拟用户 3.1.匿名用户 123456789anonymous_enable=YES|NO # 控制是否允许匿名用户登录，默认值为YES允许匿名用户登录。ftp_username= # 匿名用户所使用的系统用户名。默认此参数在配置文件中不出现，值为ftp。no_anon_password=NO # 控制匿名用户登入时是否需要密码，默认值为NO需要密码。deny_email_enable=NO # 拒绝在banned_email_file指定的文件中所列出的email地址进行登录的匿名用户。默认值为NO关闭。这对于阻击某些Dos攻击有效。如果开启需要追加以下配置banned_email_file=/etc/banned_emails.conf # 当匿名用户使用banned_email_file文件中所列出的e-mail进行登录时，被拒绝指定包含被拒绝的e-mail地址的文件，默认文件为/etc/vsftpd.banned_emails。anon_root= # 匿名用户的根目录，默认为/var/ftp/，主配置文件中默认无此项。anon_world_readable_only=YES # 默认值为YES只允许匿名用户下载可阅读的文件。NO允许匿名用户浏览整个服务器的文件anon_upload_enable=NO # 是否允许匿名用户上传文件，默认NO不允许。 除了anon_upload_enable这个参数外，匿名用户要能上传文件，还需要两个条件： 1）write_enable参数为YES; 2）在文件系统上，FTP匿名用户对某个目录有写权限 1234anon_mkdir_write_enable=NO # 是否允许匿名用户创建新目录，默认为NO不允许，同时FTP匿名用户必需对新目录的上层目录拥有写权限。anon_other_write_enable=NO # 匿名用户是否拥有除了上传和新建目录之外的其他权限，如删除、更名等。默认为NO不拥有chown_uploads=NO # 是否修改匿名用户所上传文件的所有权。默认值为NO不修改。如果改为YES匿名用户所上传的文件的所有权将改为另外一个不同的用户所有chown_username=whoever # 指定拥有匿名用户上传文件所有权的用户。此参数与chown_uploads联用。不推荐使用root用户。 3.2.本地用户 在使用FTP服务的用户中，除了匿名用户外，还有一类在FTP服务器所属主机上拥有账号的用户。VSFTPD中称此类用户为本地用户（localuser），等同于其他FTP服务器中的real用户。 123local_enable=YES # 本地系统用户是否可以登陆，默认值为YES。local_root= # 定义所有本地用户的根目录。默认为空，本地用户登录到自己的宿主目录user_config_dir=/etc/vsftpd/user.d # 定义用户个人配置文件所在的目录，配置文件名为用户名，配置格式与vsftpd.conf相同。默认为无不单独设置用户权限，虚拟用户也用这个 3.3.虚拟用户 12guest_enable=NO # 若是启动这项功能，所有的非匿名登入者都视为guest，默认值为NO关闭。如果要使用ftp虚拟用户需要启用guest_username= # 定义VSFTPD的guest用户在系统中的用户名。默认值为ftp，在使用ftp虚拟用户时建议自定义，例如ftpvuser 4.安全措施 4.1.用户登录控制 123456/etc/vsftpd/ftpusers # 改配置文件中的用户禁止登录FTP服务器。这个机制是在/etc/pam.d/vsftpd中默认设置的。pam_service_name=vsftpd # 指定vsftpd进行PAM认证时所使用的PAM配置文件名，默认值是vsftpd，默认PAM配置文件是/etc/pam.d/vsftpd，使用ftp虚拟用户时需要更改userlist_enable=NO # 是否通过userlist_file列表控制可登陆的用户，默认为NO不启用，如果启用，列表中的用户默认拒绝登录FTP服务器，在输入用户名后，不提示输入密码userlist_deny=YES # 决定禁止还是允许userlist_file指定文件中的用户登录FTP服务器，默认为YES禁止文件中的用户登录，此选项在userlist_enable选项启动后才生效，如果要允许在文件中的用户登录FTP服务器需要改为NOuserlist_file=/etc/vsftpd/user_list # userlist_enable选项指定的用户列表的文件。默认为/etc/vsftpd/user_list。tcp_wrappers=YES # 在vsftpd中使用TCP_Wrappers封装数据，默认值为YES。 4.2.目录访问控制 123456789chroot_list_enable=NO # 是否锁定用户在其宿主目录中，默认值为NO不锁定。具体的用户在chroot_list_file参数所指定的文件中列出。chroot_list_file=/etc/vsftpd/chroot_list # 指定要锁定在宿主目录中的用户，默认不设置。一行一用户，通常为/etc/vsftpd/chroot_listchroot_local_users=NO # 将本地用户锁定在其宿主目录中，默认值为NO不锁定。注意：当chroot_local_users被激活时，chroot_list_enable和chroot_local_users参数的作用将发生变化，chroot_list_file所指定文件中的用户将不被锁定在自家目录。可能带来安全上的冲突，特别是当用户拥有上传、shell访问等权限时。passwd_chroot_enable=NO # 当此选项需与chroot_local_user配合，chroot()容器的位置可以在每个用户的基础上指定。每个用户的容器来源于/etc/passwd中每个用户的自家目录字段。默认值为NO。 4.3.文件操作控制 1234567hide_ids=YES|NO # 是否隐藏文件的所有者和组信息。默认值为NO不隐藏，如果为YES，当用户使用&quot;ls -al&quot;之类的指令时，在目录列表中所有文件的拥有者和组信息都显示为ftpls_recurse_enable=YES|NO # 是否允许使用&quot;ls-R&quot;指令，默认值为NO不允许。如果在一个大型FTP站点的根目录下使用&quot;ls-R&quot;会消耗大量系统资源。write_enable=YES|NO # 是否允许使用修改文件系统的FTP的指令，默认为NO不允许，比如STOR、DELE、RNFR、RNTO、MKD、RMD、APPE以及SITEsecure_chroot_dir= # 安全沙箱目录，指向一个ftp用户无写权限的空目录，默认为/usr/share/empty。当vsftpd不需要访问文件系统时，这个目录将被作为一个安全的容器，用户将被限制在此目录中。anon_umask= # 匿名用户新增文件的umask数值。默认值为077。file_open_mode= # 上传文件的权限，默认值为0666。与chmod所使用的数值相同。如果希望上传的文件可以执行，设此值为0777。local_umask= # 本地用户新增文件时的umask数值，默认值为077。如果希望新增的文件他人可以访问的话，修改为022 5.提示信息 12345ftpd_banner=welcome # 此参数定义了登录欢迎语，预设值为无，可修改banner_file=/etc/vsftpd/banner_file # 当用户登录时会显示此文件中的内容，通常为欢迎话语或是说明。默认值为无。 # 与ftpd_banner相比，banner_file是文本文件的形式，而ftpd_banner是字串格式。banner_file选项将取代ftpd_banner选项。dirmessage_enable=YES # 特定目录的提示信息，默认为YES启用。当用户进入指定目录，如果该目录下存在message_file指定的文件，则显示出现此文档的内容，通常这个文档会放置欢迎话语，或是对该目录的说明。message_file= # dirmessage_enable选项启用时生效，指定提示内容的文档。默认为.message，以该扩展名结尾的文件 6.日志设置 1234xferlog_enable=NO # 是否启用一个日志文件，记录上传和下载，默认为NO不启用，该日志文件由xferlog_file选项指定xferlog_file=/var/log/vsftpd.log # 记录ftp日志。默认为/var/log/vsftpd.logxferlog_std_format=NO # 日志文件格式是否使用xferlog的标准格式，默认为NO不使用。默认的日志格式更为可读性，使用xferlog格式可以使用已经存在的传输统计生成器。log_ftp_protocol=NO # 是否记录所有的FTP请求和响应到日志中，这个选项一般用于调试，默认为NO不记录。使用此选项时xferlog_std_format不能被激活 7.其他设置 123456setproctitle_enable=NO # 是否在系统进程列表中显示每个会话(session)的状态，默认为NO不显示。包括挂起、下载等text_userdb_names=No # 用户使用ls -al命令时，列表信息是否显示拥有者名称而不是UID，默认为NO不显示use_localtime=NO # vsftpd显示目录列表时是否使用服务器本地时区的时间。默认为NO显示GMT时间，建议修改为YES。由ftp命令“MDTM”返回的时间值也受此选项影响。check_shell=YES # 本地用户登录时vsftpd是否检查/etc/shells文件以寻找一个有效的用户shell。默认为YES。此选项仅对不使用PAM方式的VSFTPD生效。nopriv_user=nobody # 指定一个专用的除nobody以外的用户，当VSFTPD不想要什么权限时，使用此用户身份。默认值为nobody，如果使用建议修改，因为在大多数的机器上，nobody用户被用于大量重要的事情pam_service_name= # 指明vsftpd使用用PAM验证服务时的PAM配置文件名。默认值为ftp。 文章转载来自https://www.cnblogs.com/tssc/p/9592600.html","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"vsftpd","slug":"vsftpd","permalink":"http://yoursite.com/tags/vsftpd/"}]},{"title":"不就是SELECT COUNT语句吗，竟然能被面试官虐的体无完肤","slug":"不就是SELECT-COUNT语句吗，竟然能被面试官虐的体无完肤","date":"2020-03-26T09:38:21.000Z","updated":"2022-10-21T05:58:36.868Z","comments":true,"path":"2020/03/26/不就是SELECT-COUNT语句吗，竟然能被面试官虐的体无完肤/","link":"","permalink":"http://yoursite.com/2020/03/26/不就是SELECT-COUNT语句吗，竟然能被面试官虐的体无完肤/","excerpt":"文章来自 Hollis 数据库查询相信很多人都不陌生，所有经常有人调侃程序员就是CRUD专员，这所谓的CRUD指的就是数据库的增删改查。 在数据库的增删改查操作中，使用最频繁的就是查询操作。而在所有查询操作中，统计数量操作更是经常被用到。","text":"文章来自 Hollis 数据库查询相信很多人都不陌生，所有经常有人调侃程序员就是CRUD专员，这所谓的CRUD指的就是数据库的增删改查。 在数据库的增删改查操作中，使用最频繁的就是查询操作。而在所有查询操作中，统计数量操作更是经常被用到。 关于数据库中行数统计，无论是MySQL还是Oracle，都有一个函数可以使用，那就是COUNT。 但是，就是这个常用的COUNT函数，却暗藏着很多玄机，尤其是在面试的时候，一不小心就会被虐。不信的话请尝试回答下以下问题： 1、COUNT有几种用法？ 2、COUNT(字段名)和COUNT()的查询结果有什么不同？ 3、COUNT(1)和COUNT()之间有什么不同？ 4、COUNT(1)和COUNT()之间的效率哪个更高？ 5、为什么《阿里巴巴Java开发手册》建议使用COUNT() 6、MySQL的MyISAM引擎对COUNT()做了哪些优化？ 7、MySQL的InnoDB引擎对COUNT()做了哪些优化？ 8、上面提到的MySQL对COUNT()做的优化，有一个关键的前提是什么？ 9、SELECT COUNT() 的时候，加不加where条件有差别吗？ 10、COUNT(*)、COUNT(1)和COUNT(字段名)的执行过程是怎样的？ 以上10道题，如果您可以全部准确无误的回答的话，那说明你真的很了解COUNT函数了，如果有哪些知识点是不了解的，那么本文正好可以帮你答疑解惑。 认识COUNT 关于COUNT函数，在MySQL官网中有详细介绍： 简单翻译一下： 1、COUNT(expr) ，返回SELECT语句检索的行中expr的值不为NULL的数量。结果是一个BIGINT值。 2、如果查询结果没有命中任何记录，则返回0 3、但是，值得注意的是，COUNT(*) 的统计结果中，会包含值为NULL的行数。 即以下表记录 12345678create table #bla(id int,id2 int)insert #bla values(null,null)insert #bla values(1,null)insert #bla values(null,1)insert #bla values(1,null)insert #bla values(null,1)insert #bla values(1,null)insert #bla values(null,null) 使用语句count(*),count(id),count(id2)查询结果如下： 12select count(*),count(id),count(id2)from #bla results 7 3 2 除了COUNT(id)和COUNT(*)以外，还可以使用COUNT(常量)（如COUNT(1)）来统计行数，那么这三条SQL语句有什么区别呢？到底哪种效率更高呢？为什么《阿里巴巴Java开发手册》中强制要求不让使用 COUNT(列名)或 COUNT(常量)来替代 COUNT(*)呢？ COUNT(列名)、COUNT(常量)和COUNT(*)之间的区别 前面我们提到过COUNT(expr)用于做行数统计，统计的是expr不为NULL的行数，那么COUNT(列名)、 COUNT(常量) 和 COUNT()这三种语法中，expr分别是列名、 常量 和 。 那么列名、 常量 和 *这三个条件中，常量 是一个固定值，肯定不为NULL。*可以理解为查询整行，所以肯定也不为NULL，那么就只有列名的查询结果有可能是NULL了。 所以， COUNT(常量) 和 COUNT(*)表示的是直接查询符合条件的数据库表的行数。而COUNT(列名)表示的是查询符合条件的列的值不为NULL的行数。 除了查询得到结果集有区别之外，COUNT(*)相比COUNT(常量) 和 COUNT(列名)来讲，COUNT(*)是SQL92定义的标准统计行数的语法，因为他是标准语法，所以MySQL数据库对他进行过很多优化。 SQL92，是数据库的一个ANSI/ISO标准。它定义了一种语言（SQL）以及数据库的行为（事务、隔离级别等）。 COUNT(*)的优化 前面提到了COUNT(*)是SQL92定义的标准统计行数的语法，所以MySQL数据库对他进行过很多优化。那么，具体都做过哪些事情呢？ 这里的介绍要区分不同的执行引擎。MySQL中比较常用的执行引擎就是InnoDB和MyISAM。 MyISAM和InnoDB有很多区别，其中有一个关键的区别和我们接下来要介绍的COUNT(*)有关，那就是MyISAM不支持事务，MyISAM中的锁是表级锁；而InnoDB支持事务，并且支持行级锁。 因为MyISAM的锁是表级锁，所以同一张表上面的操作需要串行进行，所以，MyISAM做了一个简单的优化，那就是它可以把表的总行数单独记录下来，如果从一张表中使用COUNT(*)进行查询的时候，可以直接返回这个记录下来的数值就可以了，当然，前提是不能有where条件。 MyISAM之所以可以把表中的总行数记录下来供COUNT(*)查询使用，那是因为MyISAM数据库是表级锁，不会有并发的数据库行数修改，所以查询得到的行数是准确的。 但是，对于InnoDB来说，就不能做这种缓存操作了，因为InnoDB支持事务，其中大部分操作都是行级锁，所以可能表的行数可能会被并发修改，那么缓存记录下来的总行数就不准确了。 但是，InnoDB还是针对COUNT(*)语句做了些优化的。 在InnoDB中，使用COUNT(*)查询行数的时候，不可避免的要进行扫表了，那么，就可以在扫表过程中下功夫来优化效率了。 从MySQL 8.0.13开始，针对InnoDB的 SELECT COUNT(*) FROM tbl_name 语句，确实在扫表的过程中做了一些优化。前提是查询语句中不包含WHERE或GROUP BY等条件。 我们知道，COUNT(*)的目的只是为了统计总行数，所以，他根本不关心自己查到的具体值，所以，他如果能够在扫表的过程中，选择一个成本较低的索引进行的话，那就可以大大节省时间。 我们知道，InnoDB中索引分为聚簇索引（主键索引）和非聚簇索引（非主键索引），聚簇索引的叶子节点中保存的是整行记录，而非聚簇索引的叶子节点中保存的是该行记录的主键的值。 所以，相比之下，非聚簇索引要比聚簇索引小很多，所以MySQL会优先选择最小的非聚簇索引来扫表。所以，当我们建表的时候，除了主键索引以外，创建一个非主键索引还是有必要的。 至此，我们介绍完了MySQL数据库对于COUNT(*)的优化，这些优化的前提都是查询语句中不包含WHERE以及GROUP BY条件。 COUNT(*)和COUNT(1) 介绍完了COUNT()，接下来看看COUNT(1)，对于，这二者到底有没有区别，网上的说法众说纷纭。 有的说COUNT()执行时会转换成COUNT(1)，所以COUNT(1)少了转换步骤，所以更快。 还有的说，因为MySQL针对COUNT(*)做了特殊优化，所以COUNT(*)更快。 那么，到底哪种说法是对的呢？看下MySQL官方文档是怎么说的： InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference. 画重点：same way , no performance difference。所以，对于COUNT(1)和COUNT(*)，MySQL的优化是完全一样的，根本不存在谁比谁快！ 那既然COUNT(*)和COUNT(1)一样，建议用哪个呢？ 建议使用COUNT(*)！因为这个是SQL92定义的标准统计行数的语法，而且本文只是基于MySQL做了分析，关于Oracle中的这个问题，也是众说纷纭的呢。 COUNT(字段) 最后，就是我们一直还没提到的COUNT(字段)，他的查询就比较简单粗暴了，就是进行全表扫描，然后判断指定字段的值是不是为NULL，不为NULL则累加。 相比COUNT(*)，COUNT(字段)多了一个步骤就是判断所查询的字段是否为NULL，所以他的性能要比COUNT(*)慢。 总结 本文介绍了COUNT函数的用法，主要用于统计表行数。主要用法有COUNT(*)、COUNT(字段)和COUNT(1)。 因为COUNT(*)是SQL92定义的标准统计行数的语法，所以MySQL对他进行了很多优化，MyISAM中会直接把表的总行数单独记录下来供COUNT(*)查询，而InnoDB则会在扫表的时候选择最小的索引来降低成本。当然，这些优化的前提都是没有进行where和group的条件查询。 在InnoDB中COUNT(*)和COUNT(1)实现上没有区别，而且效率一样，但是COUNT(字段)需要进行字段的非NULL判断，所以效率会低一些。 因为COUNT(*)是SQL92定义的标准统计行数的语法，并且效率高，所以请直接使用COUNT(*)查询表的行数！ 参考资料： https://dev.mysql.com/doc/refman/8.0/en/group-by-functions.html#function_count 《极客时间——MySQL实战45讲》","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"http://yoursite.com/tags/Oracle/"},{"name":"COUNT","slug":"COUNT","permalink":"http://yoursite.com/tags/COUNT/"}]},{"title":"Oracle索引","slug":"Oracle索引","date":"2020-03-23T02:41:40.000Z","updated":"2022-10-21T06:09:13.495Z","comments":true,"path":"2020/03/23/Oracle索引/","link":"","permalink":"http://yoursite.com/2020/03/23/Oracle索引/","excerpt":"索引的作用相当于图书的目录，可以根据目录中的页码快速找到所需的内容。 在没有创建索引之前，如果要按照用户名字段username全表查询一条用户数据，就要必须在全表都搜索一遍；在username上创建索引，Oracle会对全表进行一次搜索，将每条记录的username按照顺序排序，然后构建索引条目（name和rowid），存储到索引段中。在接下来查找username等于某个值时即可直接查找到相应的地方。","text":"索引的作用相当于图书的目录，可以根据目录中的页码快速找到所需的内容。 在没有创建索引之前，如果要按照用户名字段username全表查询一条用户数据，就要必须在全表都搜索一遍；在username上创建索引，Oracle会对全表进行一次搜索，将每条记录的username按照顺序排序，然后构建索引条目（name和rowid），存储到索引段中。在接下来查找username等于某个值时即可直接查找到相应的地方。 文章来自 FREE教程 既然我们都知道建立索引有利于查询速率的提升，那是不是所有字段都可以加上索引。这是万万不行的，建立索引不仅仅要浪费空间来存储索引表，当数据量较少时，直接查询数据比经过查询索引表再定位到表数据的速度更快。索引可以提高查询的效率，但是在数据增删改时需要更新索引，因此索引对增删改时会有负面影响。所以要根据实际情况， 考虑好再建立索引。 何时建立索引 那何时建立索引，下面大概介绍几点，其余的得在实际应用和开发过程中，酌情考虑： 1、Oracle 数据库会为表的主键和包含唯一约束的列自动创建索引，所以在建立唯一约束时，可以考虑该列是否必要建立。是否经常要作为查询条件。 2、如果某个表的数据量较大（十几二十万以上），某列经常作为where的查询条件，并且检索的出来的行数经常是小于总表的5%，那该列可以考虑建立索引。 3、对于两表连接的字段，应该考虑建立索引。如果经常在某表的一个字段进行Order By 则也经过进行索引。 4、不应该在小表上建立索引。上面也说过，小表之间查询的数据会比建立索引的查询速度更快，但是在某些字段，如性别：只有男、女和未知三种数据时，可以考虑位图索引，可以增加查询效率。 5、经常进行DML操作，即经常进行增删改的操作的表，创建表索引时就要权衡一下，因为建索引会导致进行DML操作时速度变慢。所以可以根据实际情况，选择某些字段建立索引，而不能盲目乱建。 索引的类别 适当的使用索引可以提高数据检索速度，那Oracle有哪些类型的索引呢？ 1、b-tree索引：Oracle数据中最常见的索引，就是b-tree索引，create index创建的normal就是b-tree索引，没有特殊的必须应用在哪些数据上。 2、bitmap位图索引：位图索引经常应用于列数据只有几个枚举值的情况，比如上面说到过的性别字段，或者我们经常开发中应用的代码字段。这个时候使用bitmap位图索引，查询效率将会最快。 3、函数索引：比如经常对某个字段做查询的时候经常是带函数操作的，那么此时建一个函数索引就有价值了。例如：trim（列名）或者substr(列名)等等字符串操作函数，这个时候可以建立函数索引来提升这种查询效率。 4、hash索引：hash索引可能是访问数据库中数据的最快方法，但它也有自身的缺点。创建hash索引必须使用hash集群，相当于定义了一个hash集群键，通过这个集群键来告诉oracle来存储表。因此，需要在创建hash集群的时候指定这个值。存储数据时，所有相关集群键的行都存储在一个数据块当中，所以只要定位到hash键，就能快速定位查询到数据的物理位置。 5、reverse反向索引：这个索引不经常使用到，但是在特定的情况下，是使用该索引可以达到意想不到的效果。如：某一列的值为{10000,10001,10021,10121,11000,....}，假如通过b-tree索引，大部分都密集发布在某一个叶子节点上，但是通过反向处理后的值将变成{00001,10001,12001,12101,00011,...}，很明显的发现他们的值变得比较随机，可以比较平均的分部在各个叶子节点上，而不是之前全部集中在某一个叶子节点上，这样子就可大大提高检索的效率。 6、分区索引和分区表的全局索引：这两个索引是应用在分区表上面的，前者的分区索引是对分区表内的单个分区进行数据索引，后者是对分区表的全表进行全局索引。分区表的介绍，可以后期再做单独详解，这里就不累述了。 创建索引 语法结构： 123456789101112create[unique]|[bitmap] index index_name --UNIQUE表示唯一索引、BITMAP位图索引on table_name(column1,column2...|[express])--express表示函数索引[tablespace tab_name] --tablespace表示索引存储的表空间[pctfree n1] --索引块的空闲空间n1[storage --存储块的空间 ( initial 64K --初始64k next 1M minextents 1 maxextents unlimited )]; Oracle要求创建索引的列不能超过32列 语法解析： 1、UNIQUE:指定索引列上的值必须是唯一的。称为唯一索引，BITMAP表示位图索引。 2、index_name：指定索引名。 3、tabl_name：指定要为哪个表创建索引。 4、column_name：指定要对哪个列创建索引。我们也可以对多列创建索引，这种索引称为组合索引。也可以是函数表达式，这种就是函数索引。 修改索引： 1、重命名索引： 1alter index index_old rename to index_new;--重新命名索引 2、合并索引、重新构造索引：我们索引建好后，经过很长一段时间的使用，索引表中存储的空间会产生一些碎片，导致索引的查询效率会有所下降，这个时候可以合并索引，原理是按照索引规则重新分类存储一下，或者也可以选择删除索引重新构造索引。 12alter index index_name coalesce;--合并索引alter index index_name rebuild;--重新构造 删除索引： 1drop index index_name; 查看索引： 1234567select t.INDEX_NAME,--索引名字 t.index_type,--索引类型 t.TABLESPACE_NAME,--表空间 t.status,--状态 t.UNIQUENESS--是否唯一索引 from all_indexes T where t.INDEX_NAME='index_name'; 案例分析： 案例1、学生信息表（stuinfo）创建的时候就对学号（stuid）设置了主键（PK_STUINFO），当我们学生信息表数据量大的情况下，我们明显发现班号（classno）需要一个索引，不仅仅是用来关联班级信息表（class）、而且经常作为查询条件，因此创建脚本如下： 123456789101112create index STUDENT.IDX_STUINFO_CLASSNO on STUDENT.STUINFO (CLASSNO) tablespace USERS pctfree 10 initrans 2 maxtrans 255 storage ( initial 64K next 1M minextents 1 maxextents unlimited ); 案例2、对于学生信息我们经常用性别作为统计条件进行对学生信息进行统计，因此我们可以在性别（sex）建立一个位图索引进行查询优化。代码如下： 123456789101112create bitmap index STUDENT.IDX_STUINFO_SEX on STUDENT.STUINFO (SEX) tablespace USERS pctfree 10 initrans 2 maxtrans 255 storage ( initial 64K next 1M minextents 1 maxextents unlimited ); 查询一下三种索引的状态： 12345678select t.INDEX_NAME, t.index_type, t.TABLESPACE_NAME, t.status, t.UNIQUENESS from all_indexes T where t.TABLE_NAME='STUINFO' AND T.OWNER='STUDENT' 结果如下：","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"http://yoursite.com/tags/Oracle/"},{"name":"索引","slug":"索引","permalink":"http://yoursite.com/tags/索引/"}]},{"title":"理解线程安全","slug":"理解线程安全","date":"2019-05-28T09:04:43.000Z","updated":"2022-10-21T06:08:19.855Z","comments":true,"path":"2019/05/28/理解线程安全/","link":"","permalink":"http://yoursite.com/2019/05/28/理解线程安全/","excerpt":"转自编程新说李新杰 不是线程的安全 面试官问：“什么是线程安全”，如果你不能很好的回答，那就请往下看吧。 论语中有句话叫“学而优则仕”，相信很多人都觉得是“学习好了可以做官”。然而，这样理解却是错的。切记望文生义。 同理，“线程安全”也不是指线程的安全，而是指内存的安全。为什么如此说呢？这和操作系统有关。 目前主流操作系统都是多任务的，即多个进程同时运行。为了保证安全，每个进程只能访问分配给自己的内存空间，而不能访问别的进程的，这是由操作系统保障的。 在每个进程的内存空间中都会有一块特殊的公共区域，通常称为堆（内存）。进程内的所有线程都可以访问到该区域，这就是造成问题的潜在原因。 假设某个线程把数据处理到一半，觉得很累，就去休息了一会，回来准备接着处理，却发现数据已经被修改了，不是自己离开时的样子了。可能被其它线程修改了。 比如把你住的小区看作一个进程，小区里的道路/绿化等就属于公共区域。你拿1万块钱往地上一扔，就回家睡觉去了。睡醒后你打算去把它捡回来，发现钱已经不见了。可能被别人拿走了。 因为公共区域人来人往，你放的东西在没有看管措施时，一定是不安全的。内存中的情况亦然如此。 所以线程安全指的是，在堆内存中的数据由于可以被任何线程访问到，在没有限制的情况下存在被意外修改的风险。 即堆内存空间在没有保护机制的情况下，对多线程来说是不安全的地方，因为你放进去的数据，可能被别的线程“破坏”。 那我们该怎么办呢？解决问题的过程其实就是一个取舍的过程，不同的解决方案有不同的侧重点。","text":"转自编程新说李新杰 不是线程的安全 面试官问：“什么是线程安全”，如果你不能很好的回答，那就请往下看吧。 论语中有句话叫“学而优则仕”，相信很多人都觉得是“学习好了可以做官”。然而，这样理解却是错的。切记望文生义。 同理，“线程安全”也不是指线程的安全，而是指内存的安全。为什么如此说呢？这和操作系统有关。 目前主流操作系统都是多任务的，即多个进程同时运行。为了保证安全，每个进程只能访问分配给自己的内存空间，而不能访问别的进程的，这是由操作系统保障的。 在每个进程的内存空间中都会有一块特殊的公共区域，通常称为堆（内存）。进程内的所有线程都可以访问到该区域，这就是造成问题的潜在原因。 假设某个线程把数据处理到一半，觉得很累，就去休息了一会，回来准备接着处理，却发现数据已经被修改了，不是自己离开时的样子了。可能被其它线程修改了。 比如把你住的小区看作一个进程，小区里的道路/绿化等就属于公共区域。你拿1万块钱往地上一扔，就回家睡觉去了。睡醒后你打算去把它捡回来，发现钱已经不见了。可能被别人拿走了。 因为公共区域人来人往，你放的东西在没有看管措施时，一定是不安全的。内存中的情况亦然如此。 所以线程安全指的是，在堆内存中的数据由于可以被任何线程访问到，在没有限制的情况下存在被意外修改的风险。 即堆内存空间在没有保护机制的情况下，对多线程来说是不安全的地方，因为你放进去的数据，可能被别的线程“破坏”。 那我们该怎么办呢？解决问题的过程其实就是一个取舍的过程，不同的解决方案有不同的侧重点。 私有的东西就不该让别人知道 现实中很多人都会把1万块钱藏着掖着，不让无关的人知道，所以根本不可能扔到大马路上。因为这钱是你的私有物品。 在程序中也是这样的，所以操作系统会为每个线程分配属于它自己的内存空间，通常称为栈内存，其它线程无权访问。这也是由操作系统保障的。 如果一些数据只有某个线程会使用，其它线程不能操作也不需要操作，这些数据就可以放入线程的栈内存中。较为常见的就是局部变量。 123456789double avgScore(double[] scores) &#123; double sum = 0; for (double score : scores) &#123; sum += score; &#125; int count = scores.length; double avg = sum / count; return avg;&#125; 这里的变量sum，count，avg都是局部变量，它们都会被分配在线程栈内存中。 假如现在A线程来执行这个方法，这些变量会在A的栈内存分配。与此同时，B线程也来执行这个方法，这些变量也会在B的栈内存中分配。 也就是说这些局部变量会在每个线程的栈内存中都分配一份。由于线程的栈内存只能自己访问，所以栈内存中的变量只属于自己，其它线程根本就不知道。 就像每个人的家只属于自己，其他人不能进来。所以你把1万块钱放到家里，其他人是不会知道的。且一般还会放到某个房间里，而不是仍在客厅的桌子上。 所以把自己的东西放到自己的私人地盘，是安全的，因为其他人无法知道。而且越隐私的地方越好。 大家不要抢，人人有份 相信聪明的你已经发现，上面的解决方案是基于“位置”的。因为你放东西的“位置”只有你自己知道（或能到达），所以东西是安全的，因此这份安全是由“位置”来保障的。 在程序里就对应于方法的局部变量。局部变量之所以是安全的，就是因为定义它的“位置”是在方法里。这样一来安全是达到了，但是它的使用范围也就被限制在这个方法里了，其它方法想用也不用了啦。 现实中往往会有一个变量需要多个方法都能够使用的情况，此时定义这个变量的“位置”就不能在方法里面了，而应该在方法外面。即从（方法的）局部变量变为（类的）成员变量，其实就是“位置”发生了变化。 那么按照主流编程语言的规定，类的成员变量不能再分配在线程的栈内存中，而应该分配在公共的堆内存中。其实也就是变量在内存中的“位置”发生了变化，由一个私有区域来到了公共区域。因此潜在的安全风险也随之而来。 那怎么保证在公共区域的东西安全呢？答案就是，大家不要抢，人人有份。设想你在街头免费发放矿泉水，来了1万人，你却只有1千瓶水，结果可想而知，一拥而上，场面失守。但如果你有10万瓶水，大家一看，水多着呢，不用着急，一个个排着队来，因为肯定会领到。 东西多了，自然就不值钱了，从另一个角度来说，也就安全了。大街上的共享单车，现在都很安全，因为太多了，到处都是，都长得一样，所以连搞破坏的人都放弃了。因此要让一个东西安全，就疯狂的copy它吧。 回到程序里，要让公共区域堆内存中的数据对于每个线程都是安全的，那就每个线程都拷贝它一份，每个线程只处理自己的这一份拷贝而不去影响别的线程的，这不就安全了嘛。相信你已经猜到了，我要表达的就是ThreadLocal类了。 123456789101112131415161718192021222324252627282930313233343536373839class StudentAssistant &#123; ThreadLocal&lt;String&gt; realName = new ThreadLocal&lt;&gt;(); ThreadLocal&lt;Double&gt; totalScore = new ThreadLocal&lt;&gt;(); String determineDegree() &#123; double score = totalScore.get(); if (score &gt;= 90) &#123; return \"A\"; &#125; if (score &gt;= 80) &#123; return \"B\"; &#125; if (score &gt;= 70) &#123; return \"C\"; &#125; if (score &gt;= 60) &#123; return \"D\"; &#125; return \"E\"; &#125; double determineOptionalcourseScore() &#123; double score = totalScore.get(); if (score &gt;= 90) &#123; return 10; &#125; if (score &gt;= 80) &#123; return 20; &#125; if (score &gt;= 70) &#123; return 30; &#125; if (score &gt;= 60) &#123; return 40; &#125; return 60; &#125;&#125; 这个学生助手类有两个成员变量，realName和totalScore，都是ThreadLocal类型的。每个线程在运行时都会拷贝一份存储到自己的本地。 A线程运行的是“张三”和“90”，那么这两个数据“张三”和“90”是存储到A线程对象（Thread类的实例对象）的成员变量里去了。假设此时B线程也在运行，是“李四”和“85”，那么“李四”和“85”这两个数据是存储到了B线程对象（Thread类的实例对象）的成员变量里去了。 线程类（Thread）有一个成员变量，类似于Map类型的，专门用于存储ThreadLocal类型的数据。从逻辑从属关系来讲，这些ThreadLocal数据是属于Thread类的成员变量级别的。从所在“位置”的角度来讲，这些ThreadLocal数据是分配在公共区域的堆内存中的。 说的直白一些，就是把堆内存中的一个数据复制N份，每个线程认领1份，同时规定好，每个线程只能玩自己的那份，不准影响别人的。 需要说明的是这N份数据都还是存储在公共区域堆内存里的，经常听到的“线程本地”，是从逻辑从属关系上来讲的，这些数据和线程一一对应，仿佛成了线程自己“领地”的东西了。其实从数据所在“位置”的角度来讲，它们都位于公共的堆内存中，只不过被线程认领了而已。这一点我要特地强调一下。 其实就像大街上的共享单车。原来只有1辆，大家抢着骑，老出问题。现在从这1辆复制出N辆，每人1辆，各骑各的，问题得解。共享单车就是数据，你就是线程。骑行期间，这辆单车从逻辑上来讲是属于你的，从所在位置上来讲还是在大街上这个公共区域的，因为你发现每个小区大门口都贴着“共享单车，禁止入门”。哈哈哈哈。 共享单车是不是和ThreadLocal很像呀。再重申一遍，ThreadLocal就是，把一个数据复制N份，每个线程认领一份，各玩各的，互不影响。 只能看，不能摸 放在公共区域的东西，只是存在潜在的安全风险，并不是说一定就不安全。有些东西虽然也在公共区域放着，但也是十分安全的。比如你在大街上放一个上百吨的石头雕像，就非常安全，因为大家都弄不动它。 再比如你去旅游时，经常发现一些珍贵的东西，会被用铁栅栏围起来，上面挂一个牌子，写着“只能看，不能摸”。当然可以国际化一点，“only look，don't touch”。这也是很安全的，因为光看几眼是不可能看坏的。 回到程序里，这种情况就属于，只能读取，不能修改。其实就是常量或只读变量，它们对于多线程是安全的，想改也改不了。 1234class StudentAssistant &#123; final double passScore = 60;&#125; 比如把及格分数设定为60分，在前面加上一个final，这样所有线程都动不了它了。这就很安全了。 小节一下：以上三种解决方案，其实都是在“耍花招”。 第一种，找个只有自己知道的地方藏起来，当然安全了。 第二种，每人复制1份，各玩各的，互不影响，当然也安全了。 第三种，更狠了，直接规定，只能读取，禁止修改，当然也安全了。 是不是都在“避重就轻”呀。如果这三种方法都解决不了，该怎么办呢？Don't worry，just continue reading。 没有规则，那就先入为主 前面给出的三种方案，有点“理想化”了。现实中的情况其实是非常混乱嘈杂的，没有规则的。 比如在中午高峰期你去饭店吃饭，进门后发现只剩一个空桌子了，你心想先去点餐吧，回来就坐这里吧。当你点完餐回来后，发现已经被别人捷足先登了。 因为桌子是属于公共区域的物品，任何人都可以坐，那就只能谁先抢到谁坐。虽然你在人群中曾多看了它一眼，但它并不会记住你容颜。 解决方法就不用我说了吧，让一个人在那儿看着座位，其它人去点餐。这样当别人再来的时候，你就可以理直气壮的说，“不好意思，这个座位，我，已经占了”。 我再次相信聪明的你已经猜到了我要说的东西了，没错，就是（互斥）锁。 回到程序里，如果公共区域（堆内存）的数据，要被多个线程操作时，为了确保数据的安全（或一致）性，需要在数据旁边放一把锁，要想操作数据，先获取锁再说吧。 假设一个线程来到数据跟前一看，发现锁是空闲的，没有人持有。于是它就拿到了这把锁，然后开始操作数据，干了一会活，累了，就去休息了。 这时，又来了一个线程，发现锁被别人持有着，按照规定，它不能操作数据，因为它无法得到这把锁。当然，它可以选择等待，或放弃，转而去干别的。 第一个线程之所以敢大胆的去睡觉，就是因为它手里拿着锁呢，其它线程是不可能操作数据的。当它回来后继续把数据操作完，就可以把锁给释放了。锁再次回到空闲状态，其它线程就可以来抢这把锁了。还是谁先抢到锁谁操作数据。 1234567891011121314151617class ClassAssistant &#123; double totalScore = 60; final Lock lock = new Lock(); void addScore(double score) &#123; lock.obtain(); totalScore += score; lock.release(); &#125; void subScore(double score) &#123; lock.obtain(); totalScore -= score; lock.release(); &#125;&#125; 假定一个班级的初始分数是60分，这个班级抽出10名学生来同时参加10个不同的答题节目，每个学生答对一次为班级加上5分，答错一次减去5分。因为10个学生一起进行，所以这一定是一个并发情形。 因此加分和减分这两个方法被并发的调用，它们共同操作总分数。为了保证数据的一致性，需要在每次操作前先获取锁，操作完成后再释放锁。 相信世界充满爱，即使被伤害 再回到一开始的例子，假如你往地上仍1万块钱，是不是一定会丢呢？这要看情况了，如果是在人来人往的都市，可以说肯定会丢的。如果你跑到无人区扔地上，可以说肯定不会丢。 可以看到，都是把东西无保护的放到公共区域里，结果却相差很大。这说明安全问题还和公共区域的环境状况有关系。 比如我把数据放到公共区域的堆内存中，但是始终都只会有1个线程，也就是单线程模型，那这数据肯定是安全的。 再者说，2个线程操作同一个数据和200个线程操作同一个数据，这个数据的安全概率是完全不一样的。肯定线程越多数据不安全的概率越大，线程越少数据不安全的概率越小。取个极限情况，那就是只有1个线程，那不安全概率就是0，也就是安全的。 可能你又猜到了我想表达的内容了，没错，就是CAS。可能大家觉得既然锁可以解决问题，那就用锁得了，为啥又冒出了个CAS呢？ 那是因为锁的获取和释放是要花费一定代价的，如果在线程数目特别少的时候，可能根本就不会有别的线程来操作数据，此时你还要获取锁和释放锁，可以说是一种浪费。 针对这种“地广人稀”的情况，专门提出了一种方法，叫CAS（Compare And Swap）。就是在并发很小的情况下，数据被意外修改的概率很低，但是又存在这种可能性，此时就用CAS。 假如一个线程操作数据，干了一半活，累了，想要去休息。（貌似今天的线程体质都不太好）。于是它记录下当前数据的状态（就是数据的值），回家睡觉了。 醒来后打算继续接着干活，但是又担心数据可能被修改了，于是就把睡觉前保存的数据状态拿出来和现在的数据状态比较一下，如果一样，说明自己在睡觉期间，数据没有被人动过（当然也有可能是先被改成了其它，然后又改回来了，这就是ABA问题了），那就接着继续干。如果不一样，说明数据已经被修改了，那之前做的那些操作其实都白瞎了，就干脆放弃，从头再重新开始处理一遍。 所以CAS这种方式适用于并发量不高的情况，也就是数据被意外修改的可能性较小的情况。如果并发量很高的话，你的数据一定会被修改，每次都要放弃，然后从头再来，这样反而花费的代价更大了，还不如直接加锁呢。 这里再解释下ABA问题，假如你睡觉前数据是5，醒来后数据还是5，并不能肯定数据没有被修改过。可能数据先被修改成8然后又改回到5，只是你不知道罢了。对于这个问题，其实也很好解决，再加一个版本号字段就行了，并规定只要修改数据，必须使版本号加1。 这样你睡觉前数据是5版本号是0，醒来后数据是5版本号是0，表明数据没有被修改。如果数据是5版本号是2，表明数据被改动了2次，先改为其它，然后又改回到5。 我再次相信聪明的你已经发现了，这里的CAS其实就是乐观锁，上一种方案里的获取锁和释放锁其实就是悲观锁。乐观锁持乐观态度，就是假设我的数据不会被意外修改，如果修改了，就放弃，从头再来。悲观锁持悲观态度，就是假设我的数据一定会被意外修改，那干脆直接加锁得了。 作者观点： 前两种属于隔离法，一个是位置隔离，一个是数据隔离。 然后两种是标记法，一个是只读标记，一个是加锁标记。 最后一种是大胆法，先来怼一把试试，若不行从头再来。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://yoursite.com/categories/编程语言/"}],"tags":[{"name":"线程安全","slug":"线程安全","permalink":"http://yoursite.com/tags/线程安全/"}]},{"title":"单例模式的7种写法","slug":"单例模式的7种写法","date":"2019-04-28T08:28:57.000Z","updated":"2022-10-21T06:08:38.119Z","comments":true,"path":"2019/04/28/单例模式的7种写法/","link":"","permalink":"http://yoursite.com/2019/04/28/单例模式的7种写法/","excerpt":"文章转自公众号无敌码农 | 谁要是再问你单例模式，那就抛给他这7种写法吧！ 单例设计模式是23种设计模式中，最基础也是最常用的设计模式之一，也是面试中关于设计模式知识点考察比较高频的问题之一。说起单例模式的写法，大多数情况下出现在我们脑海中的可能就是“饿汉式”，“懒汉式”这两种写法，但是今天小码哥今天要介绍的是单例模式的7种写法，以后面试官要是再问你单例模式，那就抛给他这七种写法吧！","text":"文章转自公众号无敌码农 | 谁要是再问你单例模式，那就抛给他这7种写法吧！ 单例设计模式是23种设计模式中，最基础也是最常用的设计模式之一，也是面试中关于设计模式知识点考察比较高频的问题之一。说起单例模式的写法，大多数情况下出现在我们脑海中的可能就是“饿汉式”，“懒汉式”这两种写法，但是今天小码哥今天要介绍的是单例模式的7种写法，以后面试官要是再问你单例模式，那就抛给他这七种写法吧！ 接下来，我们就言归正传，来一一介绍这七种单例模式的写法吧！ 饿汉式 饿汉式是单例模式设计中比较经典的实现方式。实现代码如下： 1234567891011121314151617//final不允许被继承public final class SingleTonEhangshi &#123; //实例变量 private byte[] data = new byte[1024]; //在定义实例对象时直接初始化 private static SingleTonEhangshi instance = new SingleTonEhangshi(); //私有化构造函数，不允许外部NEW private SingleTonEhangshi() &#123; &#125; public static SingleTonEhangshi getInstance() &#123; return instance; &#125;&#125; 饿汉式的实现关键在于instance作为类变量直接得到了初始化，如果我们主动使用SingleToEhangshi类，那么instance实例将会直接完成创建，包括其中的实例变量也都会得到初始化。 instance作为类变量，在类初始化的过程中会被收集进&lt;clinit&gt;()方法中，而该方法是可以100%地保证同步，也就是说instance在多线程的情况下不可能被初始化两次。但是由于instance被ClassLoader加载后很长一段时间才被使用的话，那就会意味着instance实例所开辟的堆内存会驻留很长的时间。 总体说来，如果一个类中的成员变量比较少，且占用的内存资源也不多，用饿汉式的方式实现单例模式也未尝不可，只是其无法进行懒加载。 懒汉式 所谓懒汉式就是在使用类实例的时候再去创建，也就是说用到的时候我再创建，这样就可以避免类在初始化的时候提前创建过早地占用内存空间。实现代码如下： 1234567891011121314151617181920//final不允许被继承public final class SingleTonLhangshi &#123; //实例变量 private byte[] data = new byte[1024]; //定义实例，但是不直接初始化 private static SingleTonLhangshi instance = null; //私有化构造函数，不允许外部NEW private SingleTonLhangshi() &#123; &#125; public static SingleTonLhangshi getInstance() &#123; if (null == instance) &#123; instance = new SingleTonLhangshi(); &#125; return instance; &#125;&#125; 类变量instance=null,因此当类被初始化的时候instance并不会立刻被实例化，而是在getInstance()方法被调用时判断instance实例是否被实例化，如果没有实例化在调用私有构造方法进行实例化操作。 懒汉式写法在多线程环境下，会存在同一时间多个线程同时看到null==instance的情况，从而导致instance会被实例化多次，从而无法保证单例的唯一性。 懒汉式＋同步方法 懒汉式的单例实现方式可以保证实例的懒加载，但是却无法保证实例的唯一性。在多线程环境下由于instance为共享数据，当多个线程访问使用时，需要保证数据的同步性，所以如果需要保证懒汉式实例的唯一性，我们可以通过同步的方式来实现。代码如下： 123456789101112131415161718192021//final不允许被继承public final class SingleTonLhangshiSync &#123; //实例变量 private byte[] data = new byte[1024]; //定义实例，但是不直接初始化 private static SingleTonLhangshiSync instance = null; //私有化构造函数，不允许外部NEW private SingleTonLhangshiSync() &#123; &#125; //向getInstance方法加入同步控制，每次只能有一个线程能够进入 public static synchronized SingleTonLhangshiSync getInstance() &#123; if (null == instance) &#123; instance = new SingleTonLhangshiSync(); &#125; return instance; &#125;&#125; 采用懒汉式＋数据同步的方法既满足了懒加载又能够100%保证instance实例的唯一性。但是，synchronized关键字的排它性会导致getInstance()方法同一时刻只能被一个线程访问，性能会比较低下。 Double-Check Double-Check是一种比较聪明的设计方式，它提供了一种高效的数据同步策略，那就是首次初始化的时候加锁，之后则允许多个线程同时进行getInstance()方法的调用来获得类的实例。代码如下： 12345678910111213141516171819202122232425262728293031//final不允许被继承public final class SingletonDoubleCheck &#123; //实例变量 private byte[] data = new byte[1024]; //定义实例，但是不直接初始化 private static SingletonDoubleCheck instance = null; Connection con; Socket socket; //私有化构造函数，不允许外部NEW private SingletonDoubleCheck(Connection con, Socket socket) &#123; this.con = con;//初始化 this.socket = socket;//初始化 &#125; public static SingletonDoubleCheck getInstance() &#123; //当instance为null时，进入同步代码块，同时该判断避免了每次都需要进入同步代码块，可以提高效率 if (null == instance) &#123; //只有一个线程能够获得SingletonDoubleCheck.class关联的monitor synchronized (SingletonDoubleCheck.class) &#123; //判断如果instance为null则创建 if (null == instance) &#123; instance = new SingletonDoubleCheck(); &#125; &#125; &#125; return instance; &#125;&#125; 当两个线程发现null==instance成立时，只有一个线程有资格进入同步代码块，完成对instance的初始化，随后的线程发现null==instance不成立则无须进行任何操作，以后对getInstance的访问就不会再需要进行数据同步了。 此种方式看起来是既满足了懒加载，又保证了instance实例的唯一性，并且还提供了比较高效的数据同步策略，可以允许多个线程同时对getInstance进行访问。但是这种方式在多线程的情况下，可能会引起空指针异常，这是因为如果在如上代码的构造方法中还存在初始化其他资源的情况的话，由于JVM运行时存在指令重排的情况，这些资源在实例化时顺序并无前后关系的约束，那么在这种情况下，就极有可能是instance最先被实例化，而con和socket并未完成实例化，而未完成实例化的实例在调用其方法时将会抛出空指针异常。 Volatile+Double-Check 为了解决Double-Check指令重排导致的空指针问题，可以用volatile关键字防止这种重排序的发生。因此代码只需要稍作修改就能满足多线程下的单例、懒加载以及实例的高效性了。代码如下： 1234567891011121314151617181920212223242526272829303132//final不允许被继承public final class SingletonDoubleCheck &#123; //实例变量 private byte[] data = new byte[1024]; //定义实例，但是不直接初始化 private static volatile SingletonDoubleCheck instance = null; Connection con; Socket socket; //私有化构造函数，不允许外部NEW private SingletonDoubleCheck(Connection con, Socket socket) &#123; this.con = con;//初始化 this.socket = socket;//初始化 &#125; public static SingletonDoubleCheck getInstance() &#123; //当instance为null时，进入同步代码块，同时该判断避免了每次都需要进入同步代码块，可以提高效率 if (null == instance) &#123; //只有一个线程能够获得SingletonDoubleCheck.class关联的monitor synchronized (SingletonDoubleCheck.class) &#123; //判断如果instance为null则创建 if (null == instance) &#123; instance = new SingletonDoubleCheck(); &#125; &#125; &#125; return instance; &#125;&#125; Holder方式 Holder方式完全借助了类加载的特点。代码如下： 12345678910111213141516171819//不允许被继承public final class SingletonHolder &#123; //实例变量 private byte[] data = new byte[1024]; private SingletonHolder() &#123; &#125; //在静态内部类中持有单例类的实例，并且可直接被初始化 private static class Holder &#123; private static SingletonHolder instance = new SingletonHolder(); &#125; //调用getInstance方法，事实上是获得Holder的instance静态属性 public static SingletonHolder getInstance() &#123; return Holder.instance; &#125;&#125; 在单例类中并没有instance的静态成员，而是将其放到了静态内部类Holder之中，因此单例类在初始化的过程中并不会创建SingletonHolder的实例，内部类Holder中定义了SingletonHolder的静态变量，并且直接进行了实例化，只有当Holder被主动引用的时候才会创建SingletonHolder的实例。 SingletonHolder实例的创建过程在Java程序编译时期收集至&lt;clinit&gt;()方法中，该方法又是同步方法，可以保证内存的可见性、JVM指令的顺序性和原子性。Holder方式的单例模式设计是最好的设计之一，也是目前使用比较广的设计。 枚举方式 枚举方式在很多开源框架中也应用得比较广泛，枚举类型不允许被继承，同样是线程安全的，并且只能被实例化一次，但是枚举类型不能够实现懒加载。用枚举类型，实现单例模式的代码如下： 1234567891011121314151617181920212223242526public class SingletonEnum &#123; //实例变量 private byte[] data = new byte[1024]; private SingletonEnum() &#123; &#125; //使用枚举充当Holder private enum EnumHolder &#123; INSTANCE; private SingletonEnum instance; EnumHolder() &#123; this.instance = new SingletonEnum(); &#125; private SingletonEnum getInstance() &#123; return instance; &#125; &#125; public static SingletonEnum getInstance() &#123; return EnumHolder.INSTANCE.getInstance(); &#125;&#125; 以上就是要给大家介绍的单例模式的7种写法了，虽然单例模式非常简单，但是在多线程的情况下，我们之前所设计的单例程序未必能够满足单实例、懒加载以及高性能的特点。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://yoursite.com/categories/编程语言/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"单例模式","slug":"单例模式","permalink":"http://yoursite.com/tags/单例模式/"},{"name":"设计模式","slug":"设计模式","permalink":"http://yoursite.com/tags/设计模式/"}]},{"title":"Linux定时任务","slug":"Linux定时任务","date":"2019-04-28T08:12:54.000Z","updated":"2022-10-21T06:09:39.653Z","comments":true,"path":"2019/04/28/Linux定时任务/","link":"","permalink":"http://yoursite.com/2019/04/28/Linux定时任务/","excerpt":"文章转自 菜鸟教程 inux内置的cron进程能帮我们实现这些需求，cron搭配shell脚本，非常复杂的指令也没有问题。 cron介绍 我们经常使用的是crontab命令是cron table的简写，它是cron的配置文件，也可以叫它作业列表，我们可以在以下文件夹内找到相关配置文件。 /var/spool/cron/ 目录下存放的是每个用户包括root的crontab任务，每个任务以创建者的名字命名 /etc/crontab 这个文件负责调度各种管理和维护任务。 /etc/cron.d/ 这个目录用来存放任何要执行的crontab文件或脚本。 我们还可以把脚本放在/etc/cron.hourly、/etc/cron.daily、/etc/cron.weekly、/etc/cron.monthly目录中，让它每小时/天/星期、月执行一次。","text":"文章转自 菜鸟教程 inux内置的cron进程能帮我们实现这些需求，cron搭配shell脚本，非常复杂的指令也没有问题。 cron介绍 我们经常使用的是crontab命令是cron table的简写，它是cron的配置文件，也可以叫它作业列表，我们可以在以下文件夹内找到相关配置文件。 /var/spool/cron/ 目录下存放的是每个用户包括root的crontab任务，每个任务以创建者的名字命名 /etc/crontab 这个文件负责调度各种管理和维护任务。 /etc/cron.d/ 这个目录用来存放任何要执行的crontab文件或脚本。 我们还可以把脚本放在/etc/cron.hourly、/etc/cron.daily、/etc/cron.weekly、/etc/cron.monthly目录中，让它每小时/天/星期、月执行一次。 crontab的使用 我们常用的命令如下： 1234crontab [-u username] //省略用户表表示操作当前用户的crontab -e (编辑工作表) -l (列出工作表里的命令) -r (删除工作作) 我们用 crontab -e 进入当前用户的工作表编辑，是常见的vim界面。每行是一条命令。 crontab的命令构成为 时间+动作，其时间有 分、时、日、月、周 五种，操作符有 * 取值范围内的所有数字 / 每过多少个数字 - 从X到Z ，散列数字 实例 实例1：每1分钟执行一次myCommand 1* * * * * myCommand 实例2：每小时的第3和第15分钟执行 13,15 * * * * myCommand 实例3：在上午8点到11点的第3和第15分钟执行 13,15 8-11 * * * myCommand 实例4：每隔两天的上午8点到11点的第3和第15分钟执行 13,15 8-11 */2 * * myCommand 实例5：每周一上午8点到11点的第3和第15分钟执行 13,15 8-11 * * 1 myCommand 实例6：每晚的21:30重启smb 130 21 * * * /etc/init.d/smb restart 实例7：每月1、10、22日的4 : 45重启smb 145 4 1,10,22 * * /etc/init.d/smb restart 实例8：每周六、周日的1 : 10重启smb 110 1 * * 6,0 /etc/init.d/smb restart 实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb 10,30 18-23 * * * /etc/init.d/smb restart 实例10：每星期六的晚上11 : 00 pm重启smb 10 23 * * 6 /etc/init.d/smb restart 实例11：每一小时重启smb 1* */1 * * * /etc/init.d/smb restart 实例12：晚上11点到早上7点之间，每隔一小时重启smb 1* 23-7/1 * * * /etc/init.d/smb restar","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"crontab","slug":"crontab","permalink":"http://yoursite.com/tags/crontab/"},{"name":"定时任务","slug":"定时任务","permalink":"http://yoursite.com/tags/定时任务/"}]},{"title":"Oracle的一些故障处理","slug":"Oracle的一些故障处理","date":"2019-04-08T05:17:55.000Z","updated":"2022-10-21T05:58:51.334Z","comments":true,"path":"2019/04/08/Oracle的一些故障处理/","link":"","permalink":"http://yoursite.com/2019/04/08/Oracle的一些故障处理/","excerpt":"这里汇总了一些在使用Oracle过程中遇到的问题及解决办法，一方面做为笔记帮助自己以后更快速处理问题，一方面分享处理供大家互相学习。","text":"这里汇总了一些在使用Oracle过程中遇到的问题及解决办法，一方面做为笔记帮助自己以后更快速处理问题，一方面分享处理供大家互相学习。 ⚪SP2-0667: Message file sp1.msb not found 出错原因： crontab里面的脚本，通常读取的是默认的环境变量，PATH里面不包含oracle数据库的路径。 解决办法： 1vim ~/.bashrc 把一下内容填写其中 12export ORACLE_HOME=/u01/app/oracle/product/11.2.0/dbhome_1export PATH=$ORACLE_HOME/bin:$PATH 注意，ORACLE_HOME的路径要是你计算机中oracle真实的安装地址 环境变量设置完成，执行 source ~/.bashrc 使其生效。 ⚪ORA-12162: TNS:net service name is incorrectly specified 一般出现这种错误，基本都是环境变量配置有问题，要么是没有配置正确的ORACLE_SID、ORACLE_HOME，要么是监听配置环境变量和.bash_profile环境变量配置不一致。 这里检查发现，是操作系统环境变量没有配置ORACLE_SID 因此，我们配置一下 ~/.bashrc ，在其中添加ORACLE_SID 1export ORACLE_SID=erp 注意：ORACLE_SID的值要根据自己安装oracle时设置的为准 ⚪ORA-04021: timeout occurred while waiting to lock object 情景描述: Oracle中本来有个用户NC63PM_PEIXUN1，我把这个用户名更改为了NC63PM_PEIXUN2（更改方法请参考【Oracle更改用户名和密码】），之后我想按照旧的用户名再创建一个用户，但是创建的用户的SQL语句执行了十五分钟还没执行完，并报如下的错误： ORA-04021: timeout occurred while waiting to lock object 解决办法 查看是否被锁表了 123&gt; SELECT object_name,machine,s.sid,s.serial#&gt; FROM v$locked_object l,dba_objects o ,v$session s&gt; WHERE l.object_id=o.object_id AND l.session_id=s.sid; 发现没有被锁表 查看锁表 使用 DBA_DDL_LOCKS视图获得DDL锁定信息 1&gt; SELECT * FROM dba_ddl_locks; 发现有两条关于 NC63PM_PEIXUN1 用户的锁定信息 通过 session_id 找到对应的锁表信息 1&gt; SELECT sid,serial#,status FROM v$session a WHERE a.sid in (829,392); 注：因我是kill掉这两条信息后才截的图，所以 STATUS 才为 KILLED 的。 kill这两条锁表 12&gt; ALTER SYSTEM KILL SESSION &apos;392, 5049&apos;;&gt; ALTER SYSTEM KILL SESSION &apos;829, 25287&apos;; 再次执行创建用户的脚本就能顺利执行。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"http://yoursite.com/tags/oracle/"}]},{"title":"Java基础知识小结","slug":"Java基础知识小结","date":"2019-03-26T05:44:17.000Z","updated":"2022-10-21T05:59:39.072Z","comments":true,"path":"2019/03/26/Java基础知识小结/","link":"","permalink":"http://yoursite.com/2019/03/26/Java基础知识小结/","excerpt":"写这篇文章是为了记录一下学习中被忽略的知识点，这些知识点虽然知道听说过，但对它们的概念和作用都很模糊，如果别人问起为什么，自己还真解释不上来，因此做个记录，方便以后回顾以及大家一起学习。","text":"写这篇文章是为了记录一下学习中被忽略的知识点，这些知识点虽然知道听说过，但对它们的概念和作用都很模糊，如果别人问起为什么，自己还真解释不上来，因此做个记录，方便以后回顾以及大家一起学习。 一个类的构造方法的作用是什么 若一个类没有声明构造方法,该程序能正确执行吗 ?为什么? 主要作用是完成对类对象的初始化工作。可以执行。因为一个类即使没有声明构造方法也会默认生成一个不带参数且没有任何执行动作的构造方法。 在Java中定义一个不做任何事且没有参数的构造方法的作用 Java程序在执行子类的构造方法之前，如果没有用super()来调用父类特定的构造方法，则系统会自动调用父类中没有参数的构造方法。当此时父类中只定义了有参数的构造方法而没有定义无参数的构造方法，然后在子类的构造方法中又没有使用super()来调用父类中特定的构造方法，则编译时将发生错误，因为Java程序在父类中找不到无参数的构造方法可供执行。所以我们要在父类里加上一个不做任何事且没有参数的构造方法。 重载和重写的区别 重载：发生在同一个类中，方法名必须相同，参数类型不同、个数不同、顺序不同，方法返回值和访问修饰符可以不同，发生在编译时。 重写：发生在父子类中，方法名、参数列表必须相同，返回值范围小于等于父类，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类；如果父类方法访问修饰符为private则子类就不能重写该方法。 try-catch-finally try块：用于捕获异常。其后可跟零个或多个catch块，如果没有catch块，则必须跟一个finally块。 catch块： 用于处理try捕获的异常。 finally块：无论是否捕获或者处理异常，finally块里的语句都会被执行。当在try块或catch块中遇到return语句时，finally语句块将在方法返回之前被执行。 注意，一下几种情况finally块不会被执行： 1.在finally语句块中发生了异常； 2.在前面的代码中用了System.exit()退出； 3.程序所有的线程死亡； 4.关闭CPU。 final/finally/finalize的区别 final Java中，final关键字可以用来修饰类、方法和变量（包括成员变量和局部变量） 当用final修饰一个类时，表明这个类不能被继承 当final修饰一个类中的某个方法，这个类的子类不能重写覆盖这个被修饰的类，也就是说子类是不能够存在和父类一模一样的方法。 final修饰变量，该变量表示常量，只能被赋值一次，赋值后值不能被修改。 finally 在异常处理时提供finally块来执行清楚操作。论是否捕获或者处理异常，finally块里的语句都会被执行。当在try块或catch块中遇到return语句时，finally语句块将在方法返回之前被执行。 finalize 是方法名。java技术允许使用finalize()方法在垃圾收集器将对象从内存中清除之前做必要的清理工作。这个方法是在垃圾收集器在确定了，被清理对象没有被引用的情况下调用的。 finalize是在Object类中定义的，因此，所有的类都继承了它。子类可以覆盖finalize()方法，来整理系统资源或者执行其他清理工作。 HashMap HashMap的特点 HashMap是基于哈希表的Map接口实现的。 HashMap底层采用的是Entry数组和链表实现的。 HashMap是采用key-value形式存储，其中key是可以允许为null，但是只能有一个，并且key不允许重复（如果重复则新值会覆盖旧值）。 HashMap是线程不安全的。 HashMap存入的顺序和遍历的顺序可能不一致（无序）。 HashMap保存数据的时候通过计算key的hash值来决定存储的位置。 HashMap的工作原理是什么？ HashMap是基于hashing的原理，我们使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，计算并返回的hashCode是用于找到Map数组的bucket位置来储存Node 对象。这里关键点在于指出，HashMap是在bucket中储存键对象和值对象，作为Map.Node 。 HashMap源代码 要看HashMap的源代码，我们还是从HashMap的构造方法开始一步一步的讲解。 小总结：可以看出HashMap构造的时候会初始化16个容量，并且负载因子是0.75。负载因子是什么呢？我们后面讲。 小总结：这个构造方法没有什么可说的，只是多了些验证。在这里呢？构造方法就算初始化完毕了。 我们知道HashMap最常用的方法也就是put方法了，那么下面我们就着重去探究一下put方法的实现原理，也就是对HashMap的一个透彻理解。 put方法注释说明 这段代码好好的研读，请仔细往下看： 第一步： 直接判断 table==EMPTY_TABLE ，那么这个table是什么呢？看下图： 那么这个Entry又是说什么东东呢？ 这个Entry是Map的一个静态内部类，里面最重要的属性有key、value和next三个属性值，在这里，我想大家已经猜到了，这个key和value是不是我们put的时候的key和value呢？答案是的，这个next又是干嘛用的呢？实际上这个Entry的的数据结构是一个单链表，这个next的属性的值还是这个Entry，表示的是当前的节点的下一个节点是哪个Entry。 好啦，源代码看到这里，我们知道，在put方法中，直接判断table是否为null，那么很显然到目前为止我们的table肯定是为null的，那么继续看如果table为null则要执行的代码。看下图： 哇塞，可以很直观的看到，我们实际上是初始化了一个Entry数组，而我们HashMap中的数据都是保存在了Entry[]里面了。 小总结：HashMap其实就是一个线性的Entry数组，而在Entry这个对象中保存了key和value，至于Entry对象中的next的具体作用是干嘛的，稍等做介绍哦。 第二步： 判断key是否为null。从这里可以看出，当判断key如果为null的话，并没有抛出什么异常错误，很显然HashMap是支持key为null的。那么就来看看key如果为null，会怎么处理呢？ 小总结：首先去循环遍历这个Entry数组，判断是否有key为null的情况，如果有则新值覆盖掉旧值。如果没有key为null的情况，则hash值为0，数据存储在这个Entry数组的第0个位置，也就是table[0]，具体方法可以查看addEntry方法，在这里呢，我就不再演示了。 第三步： 通过hash方法对key进行计算hash散列值，并且根据这个散列值查找这个要保存的值应该存储到table这个数组中的哪个索引位置。 第四步： 循环变量这个Entry数组，并且判断是否有重复的元素添加进去。 小总结：当去变量这个Entry数组的时候，去判断两个Entry对象的key的hash是否相同则仅仅表示它们的存储位置是相同的，然后继续判断两个Entry的key是否相等或者equals是否相等，如果条件都满足，则表示要添加的元素，key已经重复，则直接将新值覆盖掉旧值，并且return返回，一旦条件不满足，则直接将添加的元素添加到Entry对象中。 好啦，这个就是整个HashMap的底层原理。现在有的朋友可能会有产生这样的问题：如果计算的key的hash值相等，但是equals方法不相等，那么计算出来的要存储的位置不就冲突了吗？那么如果保存呢？ 解决：实际上这种担忧是有必要的，因为我们完全有可能就是说计算的key的hash值和另一个key的hash值是相等的，那么这个时候呢，如果key的equals方法又不相等，那么这个时候我要保存的value值应该存储到table中的哪个索引上呢？实际上，这种情况叫做hash冲突，学习过数据结构的朋友应该都知道，解决hash冲突的方法有很多，但是在Java中，解决冲突的办法是采用的是链表来解决的。还记得这个Entry的next属性吗？对了，这个next属性就是用来记录这个链表上的下一个Entry。 HashMap的内容摘自http://baijiahao.baidu.com/s?id=1601416041995350500&amp;wfr=spider&amp;for=pc volatile关键字的基本作用和原理 volatile关键字可以实现线程间的可见性，之所以可以实现这一点，原因在于JVM会保证被volatile修饰的变量，在线程栈中被线程使用时都会主动从共享内存(堆内存/主内存)中以实时的方式同步一次；另一方面，如果线程在工作内存中修改了volatile修饰的变量，也会被JVM要求立马刷新到共享内存中去。因此，即便某个线程修改了该变量，其他线程也可以立马感知到变化从而实现可见性. 未完待续...","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://yoursite.com/categories/编程语言/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"Oracle存储过程的实现","slug":"Oracle存储过程的实现","date":"2018-03-03T07:22:46.000Z","updated":"2022-10-21T05:59:00.010Z","comments":true,"path":"2018/03/03/Oracle存储过程的实现/","link":"","permalink":"http://yoursite.com/2018/03/03/Oracle存储过程的实现/","excerpt":"Oracle存储过程是一组为了完成特定功能的SQL语句集，经编译后存储在数据库中。用户通过指定存储过程的名字并给出参数（是否给参数要看该存储过程定义的过程中是否设置了参数）来执行它。","text":"Oracle存储过程是一组为了完成特定功能的SQL语句集，经编译后存储在数据库中。用户通过指定存储过程的名字并给出参数（是否给参数要看该存储过程定义的过程中是否设置了参数）来执行它。 准备工作 创建一张测试表 students 12345678910create table STUDENTS( id VARCHAR2(50) default sys_guid() not null, name VARCHAR2(20), age NUMBER(4,1), school VARCHAR2(100), grade VARCHAR2(50), address VARCHAR2(500), remarks VARCHAR2(500), ts CHAR(19) default to_char(sysdate,'yyyy-mm-dd hh24:mi:ss')) 插入一条测试数据。当然，也可以插入自己想插入的内容。 12insert into STUDENTS (id, name, age, school, grade, address, remarks, ts)values ('8A17DE17428E45D6E0530100007FABEB', 'xiaoming', 20, 'Changchun University of Architecture', 'Junior', 'Changchun, Jilin', null, '2019-06-12 11:07:57'); 第一个简单的存储过程 123456CREATE OR REPLACE PROCEDURE stu_schoolAS school_name VARCHAR2(100);BEGIN SELECT school INTO school_name FROM students WHERE ID='8A17DE17428E45D6E0530100007FABEB'; dbms_output.put_line(school_name);END; 执行存储过程，可以在PLSQL对象中看到我们刚才新创建的存储过程，并且没有报错，代表编译成功。 简单的存储过程 执行存储过程 1CALL stu_school(); 调用时，\"()\"是必不可少的，无论是有参数还是无参数 在SQL窗口输出页签中可以看到正确的输出内容 输出 四种存储过程 存储过程有一下四种情况 - 无参数存储过程 - 仅有输入参数存储过程 - 仅有输出参数存储过程 - 既有输入又有输出存储过程 下面将对这四种存储过程分别举例说明 无参数存储过程 无参数存储过程就如上面写的那个简单的存储过程，也可以这样写： 123456CREATE OR REPLACE PROCEDURE stu_schoolAS school_name students.school%TYPE;BEGIN SELECT school INTO school_name FROM students WHERE ID='8A17DE17428E45D6E0530100007FABEB'; dbms_output.put_line(school_name);END; 仅有输入参数存储过程 123456CREATE OR REPLACE PROCEDURE stu_address(stu_id IN students.id%TYPE)AS addr students.address%TYPE;BEGIN SELECT address INTO addr FROM students WHERE ID=stu_id; dbms_output.put_line(addr);END; 执行存储过程 1CALL stu_address('8A17DE17428E45D6E0530100007FABEB'); 仅有输入参数存储过程 仅有输出参数存储过程 12345CREATE OR REPLACE PROCEDURE stu_age(stu_age OUT students.age%TYPE)ASBEGIN SELECT age INTO stu_age FROM students WHERE ID='8A17DE17428E45D6E0530100007FABEB';END; 需要注意的是，此种存储过程不能直接通过call来调用，需要通过一下方式执行 注意，如果通过这种方式执行存储过程，要记得在存储过程中添加输出语句，不然的话，纵然执行成功，也没有结果输出。 dbms_output.put_line(stu_age); 12345DECLAREstuage students.age%TYPE;BEGIN stu_age(stuage);END; 或者通过oracle函数调用带有输出参数的存储过程 12345CREATE OR REPLACE FUNCTION get_stuage(stuage OUT NUMBER) RETURN NUMBER ISBEGIN stu_age(stuage); RETURN stuage;END; 执行函数 12345DECLARE stuage students.age%TYPE;BEGIN dbms_output.put_line('return result:' || get_stuage(stuage));END; 既有输入又有输出参数的存储过程 12345CREATE OR REPLACE PROCEDURE stu_name(stuid IN students.id%TYPE, stuname OUT students.name%TYPE)ASBEGIN SELECT NAME INTO stuname FROM students WHERE ID=stuid;END; 新建存储函数调用存储过程 12345CREATE OR REPLACE FUNCTION get_stuname(stuid IN students.id%TYPE, stuname OUT students.name%TYPE) RETURN VARCHAR2 ISBEGIN stu_name(stuid, stuname); RETURN stuname;END; 执行函数 12345DECLARE stuname students.name%TYPE;BEGIN dbms_output.put_line('The student name is:' || get_stuname('8A17DE17428E45D6E0530100007FABEB', stuname));END; Java调用存储过程 Java调用仅有输出参数的存储过程 针对存储过程 stu_age 12345CREATE OR REPLACE PROCEDURE stu_age(stu_age OUT students.age%TYPE)ASBEGIN SELECT age INTO stu_age FROM students WHERE ID='8A17DE17428E45D6E0530100007FABEB';END; Java代码如下： 123456789101112131415private void OnlyOutputProcedure() &#123; try &#123; Class.forName(DRVIER); Connection connection = DriverManager.getConnection(URL, USERNAME, PASSWORD); String sql = \"&#123;call stu_age(?)&#125;\"; CallableStatement statement = connection.prepareCall(sql); statement.registerOutParameter(1, OracleTypes.NUMBER); statement.execute(); System.out.println(statement.getInt(1)); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125;&#125; Java调用既有输入参数又有输出参数的存储过程 针对存储过程 stu_name 12345CREATE OR REPLACE PROCEDURE stu_name(stuid IN students.id%TYPE, stuname OUT students.name%TYPE)ASBEGIN SELECT NAME INTO stuname FROM students WHERE ID=stuid;END; Java代码如下： 12345678910111213141516private void InAndOutputProcedure() &#123; try &#123; Class.forName(DRVIER); Connection connection = DriverManager.getConnection(URL, USERNAME, PASSWORD); String sql = \"&#123;call stu_name(?,?)&#125;\"; CallableStatement statement = connection.prepareCall(sql); statement.setString(1, \"8A17DE17428E45D6E0530100007FABEB\"); statement.registerOutParameter(2, OracleTypes.VARCHAR); statement.execute(); System.out.println(statement.getString(2)); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125;&#125; 以上是有OUT输出参数的存储过程，Java在调用存储过程后还会获得存储过程返回的参数。那么如果存储过程没有OUT输出参数怎么办？ Java调用仅有输入参数的存储过程 1234567891011121314private void OnlyInputProcedure() &#123; try &#123; Class.forName(DRVIER); Connection connection = DriverManager.getConnection(URL, USERNAME, PASSWORD); String sql = \"&#123;call stu_address(?)&#125;\"; CallableStatement statement = connection.prepareCall(sql); statement.setString(1, \"8A17DE17428E45D6E0530100007FABEB\"); statement.execute(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125;&#125; Java调用无参的存储过程 12345678910111213private void NoParameterProcedure() &#123; try &#123; Class.forName(DRVIER); Connection connection = DriverManager.getConnection(URL, USERNAME, PASSWORD); String sql = \"&#123;call stu_school()&#125;\"; CallableStatement statement = connection.prepareCall(sql); statement.execute(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125;&#125; Java调用存储函数 创建一个存储函数 get_address 调用 123456create or replace function get_address(stuid in students.id%type) return varchar2 isstuaddress students.address%type;begin select address into stuaddress from students where id=stuid; return stuaddress;end; Java调用存储过程： 12345678910111213141516private void NoParameterProcedure() &#123; try &#123; Class.forName(DRVIER); Connection connection = DriverManager.getConnection(URL, USERNAME, PASSWORD); String sql = \"&#123;?=call get_address(?)&#125;\"; CallableStatement statement = connection.prepareCall(sql); statement.registerOutParameter(1, Types.VARCHAR); statement.setString(2, \"8A17DE17428E45D6E0530100007FABEB\"); statement.execute(); System.out.println(statement.getString(1)); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125;&#125; 这里有一个关于Oracle存储过程的PPT文档，供大家下载学习点击下载","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"http://yoursite.com/tags/Oracle/"},{"name":"存储过程","slug":"存储过程","permalink":"http://yoursite.com/tags/存储过程/"}]},{"title":"Hello World","slug":"hello-world","date":"2013-07-13T12:46:25.000Z","updated":"2022-07-25T06:26:34.853Z","comments":true,"path":"2013/07/13/hello-world/","link":"","permalink":"http://yoursite.com/2013/07/13/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new \"My New Post\" More info: Writing","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new \"My New Post\" More info: Writing ### Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[{"name":"工具","slug":"工具","permalink":"http://yoursite.com/categories/工具/"}],"tags":[{"name":"hello","slug":"hello","permalink":"http://yoursite.com/tags/hello/"},{"name":"world","slug":"world","permalink":"http://yoursite.com/tags/world/"}]}]}